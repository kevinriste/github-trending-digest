<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 09, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 09, 2026</h1>
        <nav>
            <a href="../">&larr; Back to Calendar</a>
        </nav>
    </header>
    <main>
        <article>
            <div class="repos">

            <section class="repo">
                <h3>1. <a href="https://github.com/KeygraphHQ/shannon" target="_blank">KeygraphHQ/shannon</a></h3>
                <p class="description">Fully autonomous AI hacker to find actual exploits in your web apps. Shannon has achieved a 96.15% success rate on the hint-free, source-aware XBOW Benchmark.</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">14,131 stars</span>
                    | <span class="today">3,479 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Shannon is an autonomous, white‚Äëbox AI penetration testing framework that analyzes a target application&#x27;s source code and then executes real, reproducible exploits against a running web app to confirm vulnerabilities. It targets critical OWASP categories (injection, XSS, SSRF, broken authentication/authorization) and uses a built‚Äëin browser plus command‚Äëline tooling to perform attacks and produce pentester‚Äëgrade, copy‚Äëand‚Äëpaste proof‚Äëof‚Äëconcept reports. The system is containerized (Docker), orchestrates workflows (Temporal Web UI available), parallelizes analysis and exploitation, integrates reconnaissance tools like Nmap, Subfinder, WhatWeb, and Schemathesis, and relies on LLM providers (Anthropic/Claude) for autonomous reasoning. Shannon Lite is open‚Äësource under AGPL‚Äë3.0 and white‚Äëbox only, while a commercial Shannon Pro adds an advanced LLM‚Äëpowered data‚Äëflow analysis engine for deeper code analysis.</p>
<p>Shannon benefits security teams, DevOps/CI pipelines, and independent researchers who need continuous, source‚Äëaware pentesting that delivers actionable, reproducible exploit proof rather than noisy alerts. Its automated, parallelized workflow reduces the window between shipping code and discovering real exploitable issues, and the project demonstrates efficacy (20+ critical findings in OWASP Juice Shop and a 96.15% score on a source‚Äëaware XBOW benchmark), which helps explain current interest. Lite lets teams run local or CI‚Äëbased white‚Äëbox scans, while enterprises can choose Pro for enhanced analysis and compliance integration.</p>

                </div>
            </section>

            <section class="repo">
                <h3>2. <a href="https://github.com/pydantic/monty" target="_blank">pydantic/monty</a></h3>
                <p class="description">A minimal, secure Python interpreter written in Rust for use by AI</p>
                <p class="meta">
                    <span class="language">Rust</span> |
                    <span class="stars">3,093 stars</span>
                    | <span class="today">456 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Monty is a minimal, secure Python interpreter written in Rust designed to run a constrained subset of Python code generated by LLMs. It isolates the host by blocking direct filesystem, environment, and network access and instead exposes only developer-supplied external functions; it supports async/sync calls, type checking, snapshotting of interpreter state to bytes, and resource tracking (memory, stack depth, execution time) with configurable limits. Because it has no CPython dependency and is implemented in Rust, Monty can be embedded from Rust, Python, or JavaScript, offers microsecond-scale startup latency and predictable runtime performance, and allows serializing parsed code and mid-execution state for caching or cross-process resumption. The design trades full language/stdlib compatibility for a small, auditable runtime suitable for running untrusted or machine-generated code.</p>
<p>Monty‚Äôs main value is enabling agents and code-mode workflows to execute model-written Python safely, cheaply, and with very low latency, avoiding the complexity and overhead of container-based sandboxes. It is especially useful for developers of LLM-driven agents, tool-calling frameworks, edge or multi-tenant platforms, and security-conscious teams that need deterministic, resource-controlled execution of untrusted code. Snapshotting and language bindings make Monty practical for caching, migration, and integration into systems like Pydantic AI or other agent toolsets, while its constrained feature set reduces attack surface and operational cost. The project is trending because it addresses a growing need to run LLM-generated code efficiently and securely without the heavyweight orchestration of full interpreter or container stacks.</p>

                </div>
            </section>

            <section class="repo">
                <h3>3. <a href="https://github.com/openai/skills" target="_blank">openai/skills</a></h3>
                <p class="description">Skills Catalog for Codex</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">7,157 stars</span>
                    | <span class="today">1,425 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>This repository catalogs &quot;Agent Skills&quot;‚Äîself-contained folders of instructions, scripts, and resources that Codex-based AI agents can discover and use to perform specific tasks. Its main features include a curated and experimental skills layout, automatic installation of .system skills, and a $skill-installer command that adds skills by name, folder, or GitHub directory URL; each skill carries its own LICENSE.txt and follows the Agent Skills open standard. Technically, skills are packaged as directory-based modules that Codex imports at runtime (requiring a restart to pick up new skills), enabling repeatable, shareable capabilities composed of prompts, scripts, and ancillary assets. The repository therefore acts as both a registry and distribution mechanism for modular agent behaviors.</p>
<p>The project is valuable to developers, product teams, and organizations building agent-driven automation because it centralizes reusable, testable components that speed development and reduce duplication of effort. Use cases include domain-specific automation, standardized prompt and workflow sharing, rapid prototyping of agent capabilities, and collaboration across teams that need consistent agent behavior. It‚Äôs gaining traction because modular, discoverable skills align with the broader trend toward agentization and platformization of AI tooling, making it easier to scale and govern autonomous workflows.</p>

                </div>
            </section>

            <section class="repo">
                <h3>4. <a href="https://github.com/virattt/dexter" target="_blank">virattt/dexter</a></h3>
                <p class="description">An autonomous agent for deep financial research</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">12,882 stars</span>
                    | <span class="today">1,039 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Dexter is an autonomous financial research agent that converts complex investment questions into structured, multi-step research plans, executes those steps with live market data, and iterates via self-reflection and self-validation until it produces a confident answer. Key features include intelligent task planning, autonomous tool selection for fetching income statements, balance sheets, and cash flows, built-in loop detection and step limits for safety, and a JSONL scratchpad that records every tool call and reasoning step for auditability. Technically it runs on the Bun runtime, integrates with LLM providers (OpenAI, Anthropic, etc.), market-data APIs (FinancialDatasets), optional web search (Exa/Tavily), and includes an evaluation suite that logs results to LangSmith and supports LLM-as-judge scoring.</p>
<p>Dexter is valuable to buy-side analysts, sell-side researchers, portfolio managers, fintech engineers, and anyone who needs repeatable, data-driven financial analysis because it automates data collection, reasoning, and verification while preserving a transparent audit trail. Its eval framework and replayable scratchpad make it useful for model tuning, backtesting research workflows, and compliance reviews. The project is timely‚Äîcombining LLM-driven agents with real-time market data addresses a growing demand for faster, reproducible financial research and experimentation in an open-source, MIT-licensed package.</p>

                </div>
            </section>

            <section class="repo">
                <h3>5. <a href="https://github.com/microsoft/litebox" target="_blank">microsoft/litebox</a></h3>
                <p class="description">A security-focused library OS supporting kernel- and user-mode execution</p>
                <p class="meta">
                    <span class="language">Rust</span> |
                    <span class="stars">1,516 stars</span>
                    | <span class="today">359 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>LiteBox is a sandboxing library OS that minimizes the host interface to reduce attack surface and support both kernel- and user-mode execution. It provides a Rust-y, nix/rustix-inspired &quot;North&quot; API that is bound to a pluggable &quot;South&quot; Platform interface, enabling flexible North‚ÄìSouth pairings for a variety of hosts and environments. Technically, LiteBox implements a compact library OS layer that translates standard POSIX-like calls to the underlying platform shims, allowing unmodified Linux programs and other workloads to run on heterogeneous backends (e.g., Windows, Linux sandboxes, SEV SNP, OP-TEE, LVBS). Its modular design emphasizes interoperability, security-focused surface reduction, and reuse across kernel and non-kernel scenarios.</p>
<p>The project is valuable to security engineers, OS researchers, cloud and enclave developers, and anyone needing compact, cross-platform isolation for legacy or sensitive workloads. It enables use cases such as sandboxing Linux applications on Linux, running Linux binaries on Windows, and leveraging hardware-backed isolation (SEV SNP, OP-TEE) with a consistent API, which simplifies porting and hardening. Interest is driven by growing demand for safer system-level components, Rust-based tooling, and hardware-assisted isolation, making LiteBox a timely platform for experimentation and deployment where reducing attack surface and enabling secure interop are priorities.</p>

                </div>
            </section>

            <section class="repo">
                <h3>6. <a href="https://github.com/google/langextract" target="_blank">google/langextract</a></h3>
                <p class="description">A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">24,889 stars</span>
                    | <span class="today">438 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>LangExtract is a Python library that uses large language models to turn unstructured text into structured extractions guided by user-defined prompts and few-shot examples. Its main features include precise source grounding (mapping each extraction to exact spans in the source), controlled output schemas for reliable structured results, optimized handling of long documents through chunking, parallel processing and multiple passes, and instant generation of self-contained interactive HTML visualizations. Technically it interfaces with cloud models (e.g., Google Gemini) and local runtimes (via Ollama), emits JSONL outputs, and supports production workflows like Vertex AI batch processing and custom model providers. The library emphasizes prompt-aligned examples and model-specific controls to balance text-evidence extractions versus knowledge-driven inferences.</p>
<p>This tool is valuable for teams that need auditability and scalable extraction from large corpora‚Äîclinical notes, radiology reports, legal contracts, research literature, and mass-document labeling workflows all benefit from grounded, reviewable outputs. Data scientists, NLP engineers, clinical informaticists, and product teams can use LangExtract to speed schema extraction, generate training data, and create human-reviewable extraction dashboards. It‚Äôs timely because organizations increasingly demand explainable LLM outputs, reliable schema enforcement, and efficient long-document processing while maintaining flexibility to run on preferred cloud or local models.</p>

                </div>
            </section>

            <section class="repo">
                <h3>7. <a href="https://github.com/obra/superpowers" target="_blank">obra/superpowers</a></h3>
                <p class="description">An agentic skills framework &amp; software development methodology that works.</p>
                <p class="meta">
                    <span class="language">Shell</span> |
                    <span class="stars">47,973 stars</span>
                    | <span class="today">813 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Superpowers is a software development workflow and agentic skills framework that equips coding agents (e.g., Claude, Codex, OpenCode) with composable skills and mandatory workflows to plan, implement, test, review, and finish code. It provides a skills library‚Äîbrainstorming, writing plans, subagent-driven development, test-driven development, systematic debugging, git worktrees, and code review‚Äîand enforces RED-GREEN-REFACTOR, YAGNI, and DRY principles. Technically it installs as a Claude Code plugin or via manual setup for Codex/OpenCode, stores skills in the repository, triggers skills automatically based on session context, dispatches subagents per task, and manages isolated git worktrees and test baselines. The repo also includes installation docs, contribution guidelines for adding skills, and an update mechanism via the plugin marketplace.</p>
<p>This project is valuable for teams and developers using LLM-based coding assistants who need reproducible, disciplined workflows and safer autonomous execution. It scales development by breaking work into small, tested tasks delegated to subagents while enforcing reviews and test-first practices to reduce drift and technical debt. Individual contributors, engineering teams, and AI tool integrators can use it to increase productivity, maintain code quality, and standardize agent behavior across projects. Its relevance is growing alongside adoption of agentic developer tools and the demand for auditable, reliable automation in software engineering.</p>

                </div>
            </section>

            <section class="repo">
                <h3>8. <a href="https://github.com/OpenBMB/MiniCPM-o" target="_blank">OpenBMB/MiniCPM-o</a></h3>
                <p class="description">A Gemini 2.5 Flash Level MLLM for Vision, Speech, and Full-Duplex Multimodal Live Streaming on Your Phone</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">23,489 stars</span>
                    | <span class="today">212 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>MiniCPM-o is an open-source series of on‚Äëdevice multimodal large language models (MLLMs) that take images, video, text, and audio as inputs and produce high‚Äëquality text and speech outputs end-to-end. The flagship MiniCPM-o 4.5 (~9B parameters) and the efficient MiniCPM‚ÄëV 4.0 (~4B) introduce full‚Äëduplex multimodal live streaming‚Äîsimultaneous real‚Äëtime input (video/audio) and output (speech/text)‚Äîalong with bilingual real‚Äëtime voice, voice cloning, OCR, and multilingual understanding. Technically the project provides optimized model weights plus inference tooling and demos (gguf/llama.cpp‚Äëomni, vLLM, Ollama integrations, WebRTC demo) and an official Docker image for local, low‚Äëlatency deployment on phones and Macs. It also supplies alignment and fine‚Äëtuning pipelines (e.g., RLAIF‚ÄëV) and supports quantized and multi‚Äëframework workflows for efficient on‚Äëdevice inference.</p>
<p>The project is useful to developers, researchers, and product teams building privacy‚Äësensitive, low‚Äëlatency multimodal assistants, AR/VR interactions, real‚Äëtime customer service agents, and accessibility tools that require simultaneous vision and speech understanding and generation. Because the models claim parity with high‚Äëend commercial systems while remaining small enough for local deployment, teams can prototype and ship interactive experiences without heavy cloud dependency. The extensive tooling, demos, and cookbook lower the integration and fine‚Äëtuning barrier for the open‚Äësource community. Its combination of strong multimodal capability, efficient inference, and active ecosystem support explains why it has gained traction and trending attention.</p>

                </div>
            </section>

            <section class="repo">
                <h3>9. <a href="https://github.com/likec4/likec4" target="_blank">likec4/likec4</a></h3>
                <p class="description">Visualize, collaborate, and evolve the software architecture with always actual and live diagrams from your code</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">2,437 stars</span>
                    | <span class="today">271 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>LikeC4 is a modeling language and toolchain that produces live, always-up-to-date software architecture diagrams from code and model files. Its main features include a flexible DSL inspired by the C4 Model and Structurizr, customizable element types and notation, support for arbitrary nested levels, and a CLI preview workflow (npx likec4 start) with a template repository and deployed example. Technically it parses LikeC4 model sources and generates diagrammatic outputs and web previews, enabling diagrams to be synchronized with the codebase and edited as code.</p>
<p>This project is valuable for software architects, engineering teams, and technical writers who need accurate, versioned architecture documentation for onboarding, design reviews, and continuous integration. It fits organizations that prefer ‚Äúarchitecture as code‚Äù because it reduces documentation drift, supports collaboration and customization to domain-specific notations, and integrates into developer workflows. Its open-source license, templates, tutorial, and community channels (Discord, GitHub Discussions) make adoption and contribution straightforward, which helps explain its growing interest.</p>

                </div>
            </section>

            <section class="repo">
                <h3>10. <a href="https://github.com/iOfficeAI/AionUi" target="_blank">iOfficeAI/AionUi</a></h3>
                <p class="description">Free, local, open-source 24/7 Cowork and OpenClaw for Gemini CLI, Claude Code, Codex, OpenCode, Qwen Code, Goose CLI, Auggie, and more | üåü Star if you like it!</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">13,352 stars</span>
                    | <span class="today">335 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>AionUi is an open-source desktop and WebUI platform that provides a unified graphical interface and multi-agent &quot;cowork&quot; layer for command-line AI tools (built-in Gemini CLI and auto-detection for Gemini CLI, Claude Code, Codex, Qwen, Goose, Ollama, LM Studio, etc.). Its main features include multi-session local conversation storage, multi-model switching, scheduled task automation, smart file management (batch rename, classification, merging), rich preview for 9+ formats, image generation/editing, and an extensible assistants/skills ecosystem where assistants are defined by markdown files. Technically it detects and proxies local CLI tools, runs a local server for WebUI and bot integrations (Telegram, Feishu/Lark, etc.), saves data locally for privacy, and provides customization via CSS and a skills directory to extend capabilities. The UI supports parallel conversations with independent context and real-time editable previews, enabling GUI-driven orchestration of command-line AI workflows.</p>
<p>AionUi is valuable for developers, AI practitioners, power users, and teams who want a cross-platform, privacy-preserving alternative to vendor-locked GUIs like Claude Cowork: it centralizes different model tools, automates recurring workflows, and accelerates file- and document-centric tasks (PPTX/docx generation, Excel beautification, file organization, scheduled reports). Organizations that need 24/7 unattended agents, remote access through WebUI or chat platforms, or local model experimentation will benefit from its extensibility and multi-tool support. Its open-source, free nature and built-in support for many popular models and CLIs help explain its traction among users seeking flexible, integrable AI office automation.</p>

                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>
</body>
</html>
