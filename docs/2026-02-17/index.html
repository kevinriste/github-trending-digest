<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 17, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 17, 2026</h1>
        <nav>
            <a href="../">&larr; Back to Calendar</a>
        </nav>
    </header>
    <main>
        <article>
            <div class="repos">

            <section class="repo">
                <h3>1. <a href="https://github.com/alibaba/zvec" target="_blank">alibaba/zvec</a></h3>
                <p class="description">A lightweight, lightning-fast, in-process vector database</p>
                <p class="meta">
                    <span class="language">C++</span> |
                    <span class="stars">3,853 stars</span>
                    | <span class="today">1,094 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Zvec is an open-source, in-process vector database that embeds Alibabaâ€™s Proxima vector search engine to provide low-latency, production-grade similarity search directly inside applications. Its main features include millisecond searches over billions of vectors, native support for dense and sparse embeddings, multi-vector queries, hybrid search combining semantic similarity with structured filters, and simple collection/vector schema APIs. Technically it runs as a library (no separate server) with Python and Node.js clients, letting you create/open collections, insert documents with vectors, and execute VectorQuery-based searches; it supports Linux and macOS on x86_64 and ARM64 and can be installed via pip/npm or built from source. The README emphasizes speed, minimal setup, and scalability driven by the underlying Proxima engine.</p>
<p>Zvec is valuable for teams and developers building semantic search, recommendation systems, retrieval-augmented generation (RAG) for LLMs, personalization, and edge or embedded applications that require low-latency similarity lookups without deploying external services. ML engineers, product teams, and startups benefit from its simplicity and in-process model because it reduces operational overhead while supporting hybrid queries that combine semantic relevance with structured filters for production use cases. Its focus on performance, multi-vector and dense+sparse support, and easy integration make it well-suited to the current surge in embedding-based workflows and generative AI, which is driving adoption of lightweight, high-performance vector stores.</p>

                </div>
            </section>

            <section class="repo">
                <h3>2. <a href="https://github.com/nautechsystems/nautilus_trader" target="_blank">nautechsystems/nautilus_trader</a></h3>
                <p class="description">A high-performance algorithmic trading platform and event-driven backtester</p>
                <p class="meta">
                    <span class="language">Rust</span> |
                    <span class="stars">19,842 stars</span>
                    | <span class="today">546 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>NautilusTrader is an open-source, high-performance algorithmic trading platform and event-driven backtester that lets you run identical Python strategy code in both historical simulation and live deployment. Its core components are implemented in Rust (with Cython/PyO3 bindings) for speed and safety, while exposing a Python-native environment for strategy development; the engine supports nanosecond-resolution ticks, multi-venue/multi-asset backtests, advanced order types and contingencies, optional Redis-backed persistence, and modular adapters for REST/WebSocket integrations. The architecture is event-driven and message-bus oriented, enabling granular, low-latency execution and replay of market events with type- and thread-safety guarantees. Designed for production use, it emphasizes correctness, extendability, and parity between research and operations environments.</p>
<p>The platform is valuable for quantitative traders, trading firms, algorithm developers, and researchers who need a production-grade, Python-first system that scales from research to live trading without reimplementation. It is particularly useful for HFT, market-making, statistical arbitrage, and AI training workflows (RL/ES) where performance, low-latency event handling, and reproducible backtests matter. NautilusTraderâ€™s combination of Rust performance, Python usability, modular adapters, and advanced order logic reduces operational risk and accelerates development and deployment cycles. Its alignment with trends in Python data science and growing Rust adoption makes it attractive for teams seeking modern, safe, and extensible trading infrastructure.</p>

                </div>
            </section>

            <section class="repo">
                <h3>3. <a href="https://github.com/rowboatlabs/rowboat" target="_blank">rowboatlabs/rowboat</a></h3>
                <p class="description">Open-source AI coworker, with memory</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">7,400 stars</span>
                    | <span class="today">700 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Rowboat is an open-source, local-first AI coworker that builds and maintains a long-lived knowledge graph from your email, meeting notes, and other work artifacts to help you summarize, draft, plan, and produce deliverables. It stores memory as an Obsidian-compatible vault of plain Markdown with backlinks so context is transparent, editable, and kept on your machine. Rowboat connects to services like Gmail, Calendar, Drive, meeting transcription tools, and can record voice notes, draft emails, generate PDFs and slides, and run background agents to automate recurring tasks. Technically it supports local and hosted LLMs (Ollama, LM Studio, or API-based providers) and exposes a Model Context Protocol (MCP) to integrate search, databases, and other tools.</p>
<p>The project benefits knowledge workers, product managers, executives, and small teams who need contextual continuity, private data storage, and automated task assistance. By compounding memory rather than reconstructing context each time, Rowboat reduces repetitive work, speeds meeting prep, improves email drafting, and helps capture decisions and action items reliably. Its local-first design, Obsidian compatibility, background agents, and support for local models make it attractive to privacy-conscious users, while MCP-driven extensibility aligns with the current trend toward customizable, interoperable AI assistants.</p>

                </div>
            </section>

            <section class="repo">
                <h3>4. <a href="https://github.com/steipete/gogcli" target="_blank">steipete/gogcli</a></h3>
                <p class="description">Google Suite CLI: Gmail, GCal, GDrive, GContacts.</p>
                <p class="meta">
                    <span class="language">Go</span> |
                    <span class="stars">3,590 stars</span>
                    | <span class="today">637 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>gogcli is a comprehensive, script-friendly command-line interface for interacting with a wide range of Google services â€” Gmail, Calendar, Drive, Contacts, Classroom, Chat, Sheets, Docs, Slides, Forms, Apps Script, People, Groups, Tasks, and Keep â€” exposing JSON-first output and rich subcommands for searching, sending, uploading, exporting, and managing resources. Technically it is delivered as a single native CLI binary (installable via Homebrew/Arch or built from source) that talks directly to Google REST APIs, supports both OAuth desktop flows and Workspace service-account (domain-wide delegation), and securely stores refresh tokens in OS keyrings or an encrypted keyring. The tool emphasizes least-privilege auth (optional readonly/drive-scope flags), multi-account and multi-client workflows, headless/remote authorization flows, auto-refreshing tokens, and automation-friendly features such as Pub/Sub Gmail watch and an optional Cloudflare Worker backend for email open tracking. Output is designed to be parseable for scripts and automation, with calendar outputs augmented for scripting (e.g., day-of-week fields) and command allowlisting for sandboxed/agent runs.</p>
<p>This project is valuable for power users, developers, SREs, and Workspace administrators who need reproducible, automatable access to Google Workspace services without relying on a browser UI, making it ideal for scripting, cron jobs, CI/CD pipelines, remote servers, and bulk admin tasks. Security and operations-focused features â€” secure credential storage, domain-wide delegation, least-privilege scopes, and multi-account support â€” make it suitable for teams and organizations managing multiple identities and service accounts. Its CLI-first, JSON-oriented design aligns well with modern automation practices and tooling, which helps explain adoption among users who prefer terminal-based workflows or need to integrate Google services into infrastructure-as-code and orchestration systems.</p>

                </div>
            </section>

            <section class="repo">
                <h3>5. <a href="https://github.com/openclaw/openclaw" target="_blank">openclaw/openclaw</a></h3>
                <p class="description">Your own personal AI assistant. Any OS. Any Platform. The lobster way. ðŸ¦ž</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">202,372 stars</span>
                    | <span class="today">3,873 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>OpenClaw is a local-first personal AI assistant platform that you run on your own devices to answer and act across the messaging surfaces you already use (WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage/BlueBubbles, Teams, Matrix, Zalo, WebChat, etc.). Technically it centers on a Gateway control plane (WS API) that coordinates per-agent sessions, a CLI onboarding wizard and daemon, Pi-style agent runtimes, and companion nodes/apps for macOS, iOS and Android. It integrates model auth/failover (Anthropic/OpenAI and others), a media pipeline, browser control, Canvas/A2UI for visual workspaces, and first-class tools (cron, sessions, nodes, actions) with security defaults for DM handling. Installation and development target Node â‰¥22 with npm/pnpm/bun, plus optional Tailscale exposure and declarative Nix/Docker deployment paths.</p>
<p>This project is valuable for privacy-conscious individuals, power users, and teams who want a single always-on assistant that integrates messaging, voice, browser automation, and custom skills while keeping control of data and models. Use cases include personal productivity across channels, automated ops and alerts, multi-agent routing for complex workflows, and local voice/Canvas-driven interactions on desktop and mobile. Itâ€™s trending because it combines open-source extensibility with multi-channel reach and the rising demand for private, long-context AI assistants that can orchestrate tools and devices rather than just chat.</p>

                </div>
            </section>

            <section class="repo">
                <h3>6. <a href="https://github.com/SynkraAI/aios-core" target="_blank">SynkraAI/aios-core</a></h3>
                <p class="description">Synkra AIOS: AI-Orchestrated System for Full Stack Development - Core Framework v4.0</p>
                <p class="meta">
                    <span class="language">JavaScript</span> |
                    <span class="stars">1,022 stars</span>
                    | <span class="today">205 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Synkra AIOS is a CLI-first framework that orchestrates specialized AI agents to automate fullâ€‘stack development workflows, providing a core runtime and tooling (v4.0) for planning, development and observability. Its main features include dedicated agent roles (analyst, PM, architect, scrum master, dev, QA), a twoâ€‘phase process that first generates PRDs and architecture then produces hyperâ€‘detailed story files for implementation, lifecycle hooks and IDE integrations, plus observability (SSE dashboards, logs, metrics). Technically it is a Node.js-based toolchain distributed via npx (aios-core CLI), relies on engineered prompts and humanâ€‘inâ€‘theâ€‘loop refinements, file-backed artifacts and hook adapters to integrate with multiple CLIs/IDEs, and provides install/upgrade flows that preserve project customizations.</p>
<p>The project benefits engineering teams, product managers and dev leads who need consistent, context-rich specificationâ€‘toâ€‘code handoffs and stronger automation of repetitive tasks, reducing context loss between planning and implementation. It also suits solo developers and nonâ€‘technical domains (creative writing, business strategy, education) that can leverage domainâ€‘specific agents to scale expertise quickly. Synkra is gaining attention because it combines agent orchestration, reproducible CLIâ€‘first workflows and IDE hook parity to improve developer productivity, governance and observability in AIâ€‘assisted software delivery.</p>

                </div>
            </section>

            <section class="repo">
                <h3>7. <a href="https://github.com/letta-ai/letta-code" target="_blank">letta-ai/letta-code</a></h3>
                <p class="description">The memory-first coding agent</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">1,503 stars</span>
                    | <span class="today">22 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Letta Code is a memory-first coding harness and CLI built on the Letta API that gives you a persisted coding agent rather than ephemeral sessions. It provides persistent memory, cross-model portability (Claude Sonnet/Opus 4.5, GPT-5.2-Codex, Gemini 3 Pro, GLM-4.7, etc.), and a skill system (.skills) with commands like /init, /remember, /skill, /connect and /model to configure behavior and APIs. Technically the agent stores and updates long-lived memory across sessions, supports user-supplied LLM keys or the Letta API, and can point at an external server via LETTABASEURL; /clear creates a new conversational thread while preserving the agentâ€™s learned state. The package is distributed as an npm CLI and includes tooling for skill learning and persistent agent workflows.</p>
<p>This approach is valuable for developers and teams who want a personalized, evolving coding assistant that retains project context, conventions, and learned skills over time, reducing repetitive setup and onboarding friction. Itâ€™s useful for long-lived projects, pair programming augmentation, code review assistance, and experimentation across multiple LLMs because agents remain portable and improvable. The project is timely given the rise of agent-based workflows and multi-model experimentation, which prioritize persistent memory and long-term assistant utility over single-session interactions.</p>

                </div>
            </section>

            <section class="repo">
                <h3>8. <a href="https://github.com/ruvnet/wifi-densepose" target="_blank">ruvnet/wifi-densepose</a></h3>
                <p class="description">Production-ready implementation of InvisPose - a revolutionary WiFi-based dense human pose estimation system that enables real-time full-body tracking through walls using commodity mesh routers</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">6,857 stars</span>
                    | <span class="today">344 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>WiFi-DensePose is a production-ready system that estimates dense human pose and tracks multiple people in real time using WiFi Channel State Information (CSI) instead of cameras. It fuses CSI preprocessing, phase sanitization, and feature extraction with a DensePose neural head and multi-object tracking, and exposes REST and WebSocket APIs for live streaming and control. The project includes a high-performance Rust port with validated microbenchmarks and full test coverage, and supports deployment via pip, Docker, or building from source for low-latency, resource-efficient operation.</p>
<p>This technology delivers privacy-preserving, through-wall sensing suited to healthcare (fall and vital-sign monitoring), fitness, smart homes, security, and disaster response (the WiFiâ€‘Mat module for survivor detection and triage). Enterprise featuresâ€”authentication, rate limiting, monitoringâ€”and WASM support in the Rust implementation make it attractive to commercial integrators and IoT vendors. Researchers, emergency responders, and product teams benefit from camera-less, hardware-agnostic sensing on commodity routers, and the combination of strong performance, test coverage, and practical APIs explains its growing interest.</p>

                </div>
            </section>

            <section class="repo">
                <h3>9. <a href="https://github.com/seerr-team/seerr" target="_blank">seerr-team/seerr</a></h3>
                <p class="description">Open-source media request and discovery manager for Jellyfin, Plex, and Emby.</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">9,124 stars</span>
                    | <span class="today">182 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Seerr is an open-source web application for managing media requests and discovery across Jellyfin, Plex, and Emby. It offers user import/authentication, library scanning, a customizable request UI for movies and TV (including season-level requests), and integrations with Sonarr and Radarr to automate acquisition; it supports PostgreSQL and SQLite backends, SMTP, various notification agents, and exposes an API (docs at http://localhost:5055/api-docs). Technically it runs as a backend service with a mobile-friendly frontend, connects to media servers and automation tools via their APIs, and implements granular permissions, watchlist/blocklist features, and request management stored in the database. The project is community-driven, provides migration guides from Overseerr/Jellyseerr, and includes documentation and contribution guidelines for extensibility.</p>
<p>Seerr delivers clear value to home media server administrators, community hosts, and anyone who accepts content requests by centralizing request intake, simplifying approvals, and automating downstream downloads via Sonarr/Radarr. Itâ€™s especially useful for users migrating from similar projects because of migration aids and for organizations that need role-based access, auditability, and multi-server support across Plex/Jellyfin/Emby. Its open-source development, active community, and frequent feature additions make it a trending choice for self-hosters seeking a polished, extensible request management solution.</p>

                </div>
            </section>

            <section class="repo">
                <h3>10. <a href="https://github.com/hummingbot/hummingbot" target="_blank">hummingbot/hummingbot</a></h3>
                <p class="description">Open source software that helps you create and deploy high-frequency crypto trading bots</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">16,654 stars</span>
                    | <span class="today">339 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Hummingbot is an open-source framework for designing, testing, and deploying automated crypto trading strategies across centralized and decentralized exchanges. It provides a modular architecture with standardized connectors for CLOB CEX, CLOB DEX, and AMM DEX venues, built-in strategy templates (e.g., market making and arbitrage), and a Gateway middleware to interact with AMM DEXs. Technically it is a Docker-friendly, Python-based CLI application (with Gateway in TypeScript for certain DEX integrations), communicates via REST and WebSocket APIs, supports install-from-source for development, and is distributed under the Apache 2.0 license.</p>
<p>The project is valuable for algorithmic traders, market makers, liquidity providers, researchers, and developers who need multi-venue automation, rapid connector reuse, and reproducible deployment workflows. By standardizing exchange integrations and offering backtesting, deployment, and community-maintained connectors, it reduces engineering overhead for cross-exchange strategies and on-chain/off-chain workflows. Its tractionâ€”over $34B in reported user trading volume and active open-source governanceâ€”makes it especially attractive as a collaborative platform for building and scaling crypto trading infrastructure.</p>

                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>
</body>
</html>
