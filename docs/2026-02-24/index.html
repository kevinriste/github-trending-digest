<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 24, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 24, 2026</h1>
        <nav>
            <a href="../">&larr; GitHub Calendar</a>
            <a href="../hn/2026-02-24/">Hacker News</a>
        </nav>
    </header>
    <main>
        <div class="repo-controls">
            <button id="collapse-seen-btn" type="button">Collapse Repos Not New Today</button>
            <button id="expand-all-btn" type="button">Expand All</button>
        </div>
        <p class="seen-help">Repos marked "Not new today" appeared on one or more previous daily pages.</p>
        <article>
            <div class="repos">

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>1. <a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools" target="_blank" rel="noopener noreferrer">x1xhlol/system-prompts-and-models-of-ai-tools</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, Dia &amp; v0. (And other Open Sourced) System Prompts, Internal Tools &amp; AI Models</p>
                    <p class="meta">
                        <span class="language">Unknown</span> |
                        <span class="stars">121,496</span>
                        | <span class="today">2,454 stars today</span>
                    </p>
                    <p class="history">First seen: February 23, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a large, curated collection of system prompts, internal tool instructions, and model configuration examples for a wide range of AI products (e.g., Claude Code, Comet, Replit, NotionAI, Perplexity and many others). Key features include more than 30k lines of prompts and templates, organized examples per product, and a README with contribution and support information. Technically the content is stored as plain-text prompt files, JSON/YAML or code snippets and organized into folders by tool so users can inspect, copy, and adapt configurations for experimentation or integration. The project is maintained via standard GitHub workflows (issues, updates, and a roadmap) and is intended to be searchable and extensible by contributors.</p>
<p>This collection benefits prompt engineers, AI developers, integration teams, security auditors, and researchers who need ready-made prompts, model tuning examples, and insight into real-world tool behaviors. It speeds prototyping by providing copy/pasteable templates and documented configurations that illustrate how different models and agents are instructed. The repository is trending because of rising interest in prompt engineering, reproducibility of AI behaviors, and the need for transparent examples for building, evaluating, and securing AI-driven products. Its breadth and community-oriented format make it a convenient reference for both practitioners and auditors.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>2. <a href="https://github.com/huggingface/skills" target="_blank" rel="noopener noreferrer">huggingface/skills</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">No description</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">4,214</span>
                        | <span class="today">1,451 stars today</span>
                    </p>
                    <p class="history">First seen: February 22, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository defines &quot;skills&quot;: self-contained folders that package instructions (SKILL.md with YAML frontmatter), scripts, templates, and resources so coding agents can perform common AI/ML tasks such as dataset creation, model training, evaluation, job management, and more. It includes ready-made skills (hf CLI, datasets, evaluation, jobs, model trainer, paper publisher, tool builder, Trackio) and provides installation/manifest support for multiple agent ecosystems (Claude/Claude Code, OpenAI Codex, Google Gemini CLI, Cursor) via AGENTS.md, gemini-extension.json, and Cursor plugin files. Technically, skills are interoperable artifacts that agents load to obtain step-by-step guidance and helper tooling; the repo also provides scripts to publish/regenerate manifests and CI checks to validate metadata and marketplace listings. The result is a standardized, reusable package format that lets agents orchestrate local or Hugging Face cloud workflows reliably.</p>
<p>This project is useful for ML engineers, MLOps teams, researchers, and developers who want to automate common model and dataset workflows through coding agents and the Hugging Face platform. It reduces manual orchestration, improves reproducibility, and makes it easy to share and extend operational patterns as installable agent plugins. Its momentum comes from the growing adoption of LLM-driven coding agents, the need for cross-platform interoperability, and tight integration with Hugging Face&#x27;s tooling and cloud compute, which together lower friction for running end-to-end ML tasks.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>3. <a href="https://github.com/OpenBB-finance/OpenBB" target="_blank" rel="noopener noreferrer">OpenBB-finance/OpenBB</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Financial data platform for analysts, quants and AI agents.</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">61,573</span>
                        | <span class="today">470 stars today</span>
                    </p>
                    <p class="history">First seen: February 23, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Open Data Platform (ODP) by OpenBB is an open-source toolset that consolidates proprietary, licensed, and public financial data and exposes it to multiple downstream surfaces such as Python environments for quants, OpenBB Workspace and Excel for analysts, MCP servers for AI agents, and REST APIs for other applications. Key features include a Python SDK (pip install openbb), a CLI, extensive data integrations, AI-agent support, and enterprise UI integration for visual workflows, all built around a ‚Äúconnect once, consume everywhere‚Äù philosophy. Technically it can run as a local backend (openbb-api) using FastAPI and Uvicorn (default on 127.0.0.1:6900) or be used directly as a library, enabling SDK calls, REST access, and easy integration into downstream systems. The project is community-driven, documented on GitHub, and distributed under AGPLv3.</p>
<p>The platform is valuable for data engineers, analysts, quants, AI/ML teams, fintech firms, and researchers who need to ingest, normalize, and serve heterogeneous financial datasets into analytics, dashboards, or AI agents. It‚Äôs trending because it combines open-source accessibility, broad connector coverage, and a Python-first developer experience with an enterprise UI, making it straightforward to prototype, deploy, and scale data-driven financial products and AI copilots. Active community contributions, simple local deployment, and explicit support for agent and workspace integrations further accelerate adoption.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>4. <a href="https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering" target="_blank" rel="noopener noreferrer">muratcankoylan/Agent-Skills-for-Context-Engineering</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">9,153</span>
                        | <span class="today">178 stars today</span>
                    </p>
                    <p class="history">First seen: February 24, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a curated collection of &quot;Agent Skills&quot; for context engineering that codifies practical patterns, tools, and examples to manage the information fed into LLM-based agents. Key features include foundational material on context mechanics and degradation, architectural modules for multi-agent patterns, memory systems, tool and filesystem integration, operational modules for compression/optimization and evaluation, and cognitive BDI mental-state transformations. Technically, skills are packaged as platform-agnostic modules (Claude Code marketplace plugins, Cursor/Codex/IDE rules or standalone skill files), use progressive disclosure so full skill content loads only when activated, and ship Python-pseudocode, triggers, and installation commands that let agent runtimes discover and apply relevant skills at runtime. The repo also documents attention-aware tactics (compaction, masking, caching), LLM-as-judge evaluation methods, and hosted-agent designs for sandboxed background execution.</p>
<p>This project benefits AI engineers, multi-agent architects, ops teams, and researchers who need repeatable, production-grade patterns for conserving model attention and debugging context failures. It accelerates development by turning abstract attention mechanics into actionable skills, templates, and plugin workflows that integrate with existing agent platforms. The collection is timely and trending because managing limited context windows is a growing practical bottleneck as agentic systems scale, and because the work has received academic recognition for helping bridge manual skill engineering and dynamic evolution of agent skills.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>5. <a href="https://github.com/f/prompts.chat" target="_blank" rel="noopener noreferrer">f/prompts.chat</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">a.k.a. Awesome ChatGPT Prompts. Share, discover, and collect prompts from the community. Free and open source ‚Äî self-host for your organization with complete privacy.</p>
                    <p class="meta">
                        <span class="language">HTML</span> |
                        <span class="stars">147,208</span>
                        | <span class="today">295 stars today</span>
                    </p>
                    <p class="history">First seen: February 24, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>prompts.chat is a curated, open-source library of prompt examples for AI chat models that aggregates community-contributed prompts and educational resources. Key features include a browsable prompt catalog with multiple data formats (PROMPTS.md, prompts.csv, Hugging Face dataset), an Interactive Book of Prompting, a game for kids, CLI and plugin integrations, and self-hosting with Docker support. Technically it‚Äôs a Node.js/npm project you can run via npx or clone and install; a setup wizard configures branding, themes and authentication (GitHub/Google/Azure AD), and the service exposes API/MCP endpoints for remote or local use while syncing new submissions from prompts.chat/new. The content is released under CC0 (public domain) to maximize reuse and modification.</p>
<p>Developers, prompt engineers, researchers, educators, and organizations wanting reusable, auditable or private prompt libraries will benefit from this project, as will learners using its guided materials. It‚Äôs trending due to strong community adoption and visibility (143k+ GitHub stars, academic citations, and media mentions), an easy path to self-host and integrate, and permissive licensing that encourages reuse and contribution. The combination of practical tooling, comprehensive educational content, and an active contributor base explains its rapid adoption and continued relevance.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>6. <a href="https://github.com/CompVis/stable-diffusion" target="_blank" rel="noopener noreferrer">CompVis/stable-diffusion</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A latent text-to-image diffusion model</p>
                    <p class="meta">
                        <span class="language">Jupyter Notebook</span> |
                        <span class="stars">72,525</span>
                        | <span class="today">36 stars today</span>
                    </p>
                    <p class="history">First seen: February 24, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Stable Diffusion is an open-source latent text-to-image diffusion model that generates high-quality 512x512 images by denoising in a learned latent space. Technically it conditions an 860M-parameter UNet on non-pooled CLIP ViT-L/14 text embeddings (123M parameters) and was trained on a filtered subset of LAION-5B; the model supports classifier-free guidance, PLMS/DDIM samplers, and image-to-image editing (SDEdit) and upscaling workflows. The repo includes reference sampling scripts, a Safety Checker module and invisible watermarking for outputs, pre-trained checkpoints (v1.x), and an official integration with Hugging Face Diffusers for easy inference. Checkpoint usage is governed by an OpenRAIL-M style license and the authors emphasize known biases and the need for additional safety measures in deployment.</p>
<p>Researchers, artists, and developers benefit from this project because it provides state-of-the-art image synthesis with relatively modest hardware requirements (‚âà10GB VRAM), ready-to-use checkpoints, and extensible tooling for sampling and image modification. Its open distribution and Diffusers integration have accelerated community experimentation, model fine-tuning, and creative applications, making it a focal point for both academic work and rapid prototyping. The combination of high visual fidelity, efficiency from latent diffusion, and a thriving ecosystem of scripts and integrations explains why Stable Diffusion quickly became widely adopted and discussed.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>7. <a href="https://github.com/abhigyanpatwari/GitNexus" target="_blank" rel="noopener noreferrer">abhigyanpatwari/GitNexus</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">2,018</span>
                        | <span class="today">467 stars today</span>
                    </p>
                    <p class="history">First seen: February 22, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>GitNexus is a client-side knowledge-graph engine that indexes a codebase into a graph of dependencies, call chains, clusters, and execution flows, then exposes that structure to AI agents and an interactive browser UI. It provides a CLI with an MCP server for deep agent integrations and a zero-server Web UI (WASM) so you can drop a GitHub repo or ZIP and get a navigable graph plus a Graph RAG agent. Under the hood it uses Tree-sitter for parsing, KuzuDB for graph storage, hybrid BM25+semantic search with embeddings, and exposes tools such as query, context, impact, detect_changes, rename, and raw Cypher over MCP. The system also installs agent skills and editor hooks to automatically enrich agent workflows with codebase-aware context.</p>
<p>Developers, engineering teams, and anyone building or operating AI-powered code assistants benefit because GitNexus gives agents deterministic architectural context so they stop missing dependencies, breaking call chains, or shipping blind edits. Its local-first design (persistent KuzuDB for CLI, in-browser WASM for quick exploration) preserves privacy while scaling from single-repo exploration to multi-repo MCP deployments, with integrations for Claude Code, Cursor, and OpenCode. It‚Äôs gaining traction because the rise of LLM-based developer tools has exposed a need for precise, explainable, repo-level context‚ÄîGitNexus converts code into an actionable knowledge graph that makes both small and large models more accurate and trustworthy.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>8. <a href="https://github.com/Stremio/stremio-web" target="_blank" rel="noopener noreferrer">Stremio/stremio-web</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Stremio - Freedom to Stream</p>
                    <p class="meta">
                        <span class="language">JavaScript</span> |
                        <span class="stars">9,999</span>
                        | <span class="today">272 stars today</span>
                    </p>
                    <p class="history">First seen: February 22, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Stremio Web is the web front-end for Stremio, a modern media center that helps users discover, watch and organize video content through a modular addon system. Key features include a centralized discovery interface, meta-details for content, and an addon-driven aggregation and playback model that lets the app surface streams from multiple sources. Technically it is a Node.js-based web application (requires Node.js 12+/npm 6+) with standard npm workflows (npm install, npm start for development, npm run build for production) and is distributed under the GPLv2 license. The repository provides the web UI assets and build pipeline used to run or package the client for production.</p>
<p>This project benefits end users looking for a single, extensible interface to browse and play content from diverse sources, as well as developers who want to create addons to add sources or enrich metadata. Its open-source, addon-centric design and web technology stack make it easy to extend, port, and contribute to, lowering the barrier for community-driven feature development. The simple Node/npm build process also makes it straightforward for contributors to run a development server or produce production builds. As streaming services proliferate, Stremio‚Äôs unified, extensible approach and active open-source ecosystem are key reasons for its traction.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>9. <a href="https://github.com/stan-smith/FossFLOW" target="_blank" rel="noopener noreferrer">stan-smith/FossFLOW</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Make beautiful isometric infrastructure diagrams</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">18,611</span>
                        | <span class="today">430 stars today</span>
                    </p>
                    <p class="history">First seen: February 22, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>FossFLOW is an open-source Progressive Web App for creating beautiful isometric infrastructure diagrams in the browser, built with React and the Isoflow library (forked/published as fossflow on npm). It offers a component library, drag-and-drop canvas, a connector tool with click or drag modes, autosave, session and export/import storage, and optional server-backed persistence via a Docker image. Technically it is organized as a monorepo with packages/fossflow-lib (React component library built with Webpack) and packages/fossflow-app (PWA built with RSBuild), and includes npm scripts for development, building, testing, linting, and publishing. Documentation, contribution guidelines, and E2E test tooling are provided to support development and deployment.</p>
<p>Network architects, DevOps engineers, technical writers, educators, and UI designers benefit from FossFLOW because it enables fast production of consistent, attractive isometric diagrams and the library can be embedded into other projects or used standalone. It‚Äôs gaining traction due to its modern, accessible stack (React + PWA), offline and auto-save convenience, easy local or containerized deployment, and the ability to export/import or persist diagrams for collaboration and documentation. The MIT license, clear contribution workflow, and npm/Docker distribution further lower adoption barriers and encourage community-driven improvements.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>10. <a href="https://github.com/VectifyAI/PageIndex" target="_blank" rel="noopener noreferrer">VectifyAI/PageIndex</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">16,941</span>
                        | <span class="today">624 stars today</span>
                    </p>
                    <p class="history">First seen: February 03, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>PageIndex is an open-source, vectorless RAG system that builds a hierarchical, table-of-contents style tree index from long documents and uses LLMs to perform reasoning-driven retrieval via tree search rather than vector similarity. It parses PDFs (or markdown and page images), generates node metadata and summaries, and performs agentic in-context searches over the tree to locate the most relevant sections. Core features include no vector DB, no artificial chunking, and explainable, traceable retrieval with page/section references; an optional vision-native pipeline works directly on page images without OCR. The repository provides a CLI (runpageindex.py) with configurable model and node/page settings and can be run locally or integrated via API/MCP for chat-style document analysis.</p>
<p>PageIndex is especially useful for professionals and teams working with long, structured documents‚Äîfinance, legal, regulatory, technical manuals, and academic texts‚Äîwhere relevance requires multi-step reasoning rather than surface-level semantic similarity. By simulating human navigation and exposing reasoning paths it improves precision, auditability, and interpretability; the authors report a 98.7% result on the FinanceBench benchmark versus vector-based approaches. It reduces dependency on vector databases and chunking, simplifies pipelines (including OCR-free vision workflows), and is well suited to enterprise, research, and developer workflows that need auditable, high-precision retrieval. The approach is trending because it leverages modern LLM reasoning to address limitations of approximate semantic search for complex, domain-specific documents.</p>
                    </div>
                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>

<script>
(() => {
    const readKey = "gtd:read_days:gh:v1";
    const dayStr = "2026-02-24";

    let stored = [];
    try {
        stored = JSON.parse(localStorage.getItem(readKey) || "[]");
        if (!Array.isArray(stored)) {
            stored = [];
        }
    } catch (_err) {
        stored = [];
    }

    if (!stored.includes(dayStr)) {
        stored.push(dayStr);
        stored.sort();
        localStorage.setItem(readKey, JSON.stringify(stored));
    }

    const collapseParam = new URLSearchParams(window.location.search).get("collapse_seen");
    const collapseSeen = collapseParam === "0" ? false : true;

    function setCollapsed(repoEl, collapsed) {
        repoEl.classList.toggle("collapsed", collapsed);
        const button = repoEl.querySelector(".repo-toggle");
        if (button) {
            button.textContent = collapsed ? "Show details" : "Hide details";
            button.setAttribute("aria-expanded", String(!collapsed));
        }
    }

    const repos = Array.from(document.querySelectorAll("section.repo[data-seen-before]"));

    repos.forEach((repoEl) => {
        const toggle = repoEl.querySelector(".repo-toggle");
        if (!toggle) {
            return;
        }

        toggle.addEventListener("click", () => {
            setCollapsed(repoEl, !repoEl.classList.contains("collapsed"));
        });
    });

    const collapseBtn = document.getElementById("collapse-seen-btn");
    const expandBtn = document.getElementById("expand-all-btn");

    if (collapseBtn) {
        collapseBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => {
                if (repoEl.dataset.seenBefore === "1") {
                    setCollapsed(repoEl, true);
                }
            });
        });
    }

    if (expandBtn) {
        expandBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => setCollapsed(repoEl, false));
        });
    }

    if (collapseSeen) {
        repos.forEach((repoEl) => {
            if (repoEl.dataset.seenBefore === "1") {
                setCollapsed(repoEl, true);
            }
        });
    }
})();
</script>

</body>
</html>
