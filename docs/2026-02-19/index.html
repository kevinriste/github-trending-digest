<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 19, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 19, 2026</h1>
        <nav>
            <a href="../">&larr; GitHub Calendar</a>
            <a href="../hn/2026-02-19/">Hacker News</a>
        </nav>
    </header>
    <main>
        <div class="repo-controls">
            <button id="collapse-seen-btn" type="button">Collapse Repos Not New Today</button>
            <button id="expand-all-btn" type="button">Expand All</button>
        </div>
        <p class="seen-help">Repos marked "Not new today" appeared on one or more previous daily pages.</p>
        <article>
            <div class="repos">

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>1. <a href="https://github.com/alibaba/zvec" target="_blank" rel="noopener noreferrer">alibaba/zvec</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A lightweight, lightning-fast, in-process vector database</p>
                    <p class="meta">
                        <span class="language">C++</span> |
                        <span class="stars">4,983</span>
                        | <span class="today">502 stars today</span>
                    </p>
                    <p class="history">First seen: February 15, 2026 | Consecutive daily streak: 5 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Zvec is an open-source, in-process vector database that embeds Alibaba’s Proxima vector search engine to provide low-latency, production-grade similarity search directly inside applications. Its main features include millisecond searches over billions of vectors, native support for dense and sparse embeddings, multi-vector queries, hybrid search combining semantic similarity with structured filters, and simple collection/vector schema APIs. Technically it runs as a library (no separate server) with Python and Node.js clients, letting you create/open collections, insert documents with vectors, and execute VectorQuery-based searches; it supports Linux and macOS on x86_64 and ARM64 and can be installed via pip/npm or built from source. The README emphasizes speed, minimal setup, and scalability driven by the underlying Proxima engine.</p>
<p>Zvec is valuable for teams and developers building semantic search, recommendation systems, retrieval-augmented generation (RAG) for LLMs, personalization, and edge or embedded applications that require low-latency similarity lookups without deploying external services. ML engineers, product teams, and startups benefit from its simplicity and in-process model because it reduces operational overhead while supporting hybrid queries that combine semantic relevance with structured filters for production use cases. Its focus on performance, multi-vector and dense+sparse support, and easy integration make it well-suited to the current surge in embedding-based workflows and generative AI, which is driving adoption of lightweight, high-performance vector stores.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>2. <a href="https://github.com/p-e-w/heretic" target="_blank" rel="noopener noreferrer">p-e-w/heretic</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Fully automatic censorship removal for language models</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">8,128</span>
                        | <span class="today">946 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Heretic is a tool for automatically removing censorship (safety alignment) from transformer-based language models by applying directional ablation (aka &quot;abliteration&quot;) combined with a TPE-based parameter optimizer implemented with Optuna. The system automatically searches for abliteration parameters that co-minimize the number of refusals on &quot;harmful&quot; prompts and the KL divergence from the original model on &quot;harmless&quot; prompts, producing decensored models that retain as much capability as possible without costly post-training. It supports most dense and many multimodal and MoE architectures, includes bitsandbytes quantization to reduce VRAM requirements, and provides built-in benchmarking, evaluation, saving/uploading to Hugging Face, and an interactive test/chat option. Optional research features expose interpretability tooling such as PaCMAP projections of residuals, residual-geometry metrics, layer-wise plots, and animations to study how harmful/harmless signals evolve through the network.</p>
<p>Heretic benefits researchers and engineers who want to study or deploy models with fewer safety refusals while preserving original capabilities, as well as hobbyists and operators constrained by GPU memory who can leverage quantization and automatic configuration. It is trending because it automates a previously expert-driven process, reporting abliterations that match or outperform manual efforts on refusal suppression with lower KL damage, and because community-shared decensored models and positive user feedback have driven visibility. Its combination of practical usability, research-focused diagnostics, and competitive empirical results makes it attractive to both the interpretability community and practitioners seeking controllable model behavior.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>3. <a href="https://github.com/OpenCTI-Platform/opencti" target="_blank" rel="noopener noreferrer">OpenCTI-Platform/opencti</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Open Cyber Threat Intelligence Platform</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">8,743</span>
                        | <span class="today">281 stars today</span>
                    </p>
                    <p class="history">First seen: February 19, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>OpenCTI is an open-source cyber threat intelligence platform that helps organizations structure, store, link, and visualize both technical (TTPs, observables) and non-technical (attribution, victimology) threat information using a knowledge schema based on STIX2. Key features include a GraphQL API, a UX-oriented web frontend, import/export capabilities (CSV, STIX2 bundles), automated relation inference, and connectors to tools like MISP, TheHive and MITRE ATT&amp;CK, with optional Enterprise-only features. Technically it is a modern web application deployable via Docker, Helm, Terraform or manual install, integrates external services such as OpenStreetMap for mapping, and collects anonymous telemetry to improve the platform.</p>
<p>Security operations centers, threat intelligence teams, incident responders, and MSSPs benefit from OpenCTI because it centralizes diverse intelligence sources, enforces structured schemas, links artifacts to primary sources, and streamlines analysis and sharing across tools. It is trending due to strong STIX2 interoperability, a developer-friendly GraphQL API, a growing ecosystem of connectors, active community and enterprise development, and straightforward deployment/demo options that lower adoption barriers. The project’s open-source nature, extensibility, and focus on inference and visualization make it appealing for organizations building automated, collaborative CTI workflows.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>4. <a href="https://github.com/QwenLM/qwen-code" target="_blank" rel="noopener noreferrer">QwenLM/qwen-code</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">An open-source AI agent that lives in your terminal.</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">18,927</span>
                        | <span class="today">95 stars today</span>
                    </p>
                    <p class="history">First seen: February 19, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Qwen Code is an open-source AI agent that runs in your terminal to help you explore large codebases, automate repetitive development tasks, and generate or refactor code, optimized for Qwen3-Coder. It provides an interactive terminal UI, headless mode for scripts/CI, IDE integrations (VS Code, Zed, JetBrains) and a TypeScript SDK, and includes built-in agent tools (Skills, SubAgents) to support an agentic workflow. Technically it’s a Node.js-based CLI that connects to LLMs via multiple protocols (OpenAI-, Anthropic-, Google GenAI-compatible endpoints or Qwen OAuth), with authentication via API keys or OAuth and local credential caching; configuration is managed through ~/.qwen/settings.json. The tool orchestrates model requests, session/history management (compressing history to save tokens), and can be installed via a one-line installer, npm, or Homebrew.</p>
<p>Developers, code reviewers, and engineering teams who need faster onboarding, automated refactoring, test generation, or CI automation will benefit most from Qwen Code because it brings LLM capabilities directly into existing developer workflows. Its headless mode and SDK make it suitable for automation and custom tooling, while IDE integrations keep the experience familiar. The project is trending due to being fully open-source and co-evolving with Qwen models, offering a generous OAuth free tier alongside multi-provider support, and prioritizing a terminal-first, extensible agent experience that integrates with popular development environments. Recent launches like Qwen3.5-Plus and broad protocol compatibility have further increased adoption and community momentum.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>5. <a href="https://github.com/NirDiamant/RAG_Techniques" target="_blank" rel="noopener noreferrer">NirDiamant/RAG_Techniques</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.</p>
                    <p class="meta">
                        <span class="language">Jupyter Notebook</span> |
                        <span class="stars">25,329</span>
                        | <span class="today">292 stars today</span>
                    </p>
                    <p class="history">First seen: February 19, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a comprehensive collection of advanced Retrieval-Augmented Generation (RAG) techniques, providing runnable scripts, documentation, and practical implementation guidance to enhance retrieval-plus-generation pipelines. Key features include foundational workflows (simple RAG, CSV ingestion), query enhancement (query rewriting, sub-query decomposition, HyDE), context and chunking strategies (fixed chunk size, proposition generation, contextual chunk headers), and novel embedding approaches like HyPE that precompute hypothetical prompts for faster, more aligned retrieval. Technically it combines document chunking, embedding/indexing, synthetic-question generation or precomputed question-question matching, and LLM-driven validation/grading to improve relevance and factual grounding. The project emphasizes reproducibility with code examples, documentation, and contribution guidance so practitioners can benchmark and integrate these methods into production systems.</p>
<p>Researchers, ML engineers, and teams building knowledge-grounded assistants, search-augmented apps, or enterprise QA systems will benefit because the repo consolidates proven patterns and ready-to-run examples that raise retrieval precision, reduce inference costs, and improve answer fidelity. It’s trending due to the wider industry shift toward RAG for scalable, context-aware LLM applications and the attractiveness of methods like HyDE/HyPE that improve alignment while controlling compute overhead. Active community channels, tutorials, and regular updates further accelerate adoption by making it straightforward to experiment, adapt, and operationalize these techniques across domains.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>6. <a href="https://github.com/harvard-edge/cs249r_book" target="_blank" rel="noopener noreferrer">harvard-edge/cs249r_book</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Introduction to Machine Learning Systems</p>
                    <p class="meta">
                        <span class="language">JavaScript</span> |
                        <span class="stars">19,799</span>
                        | <span class="today">690 stars today</span>
                    </p>
                    <p class="history">First seen: February 19, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This project is an open &quot;learning stack&quot; and living textbook that teaches AI engineering by combining a textbook source with runnable tooling: TinyTorch (a minimal teaching framework), benchmarking suites, and hardware lab kits for edge devices. Key features include modular chapters that bridge ML concepts to systems topics (memory, latency, quantization, MLOps), reference implementations (autograd, optimizers, attention), hands‑on modules from CNNs to transformers, and reproducible benchmarks (e.g., MLPerf-style experiments). Technically it ships code, labs, and deployment instructions so learners can build, measure, and deploy models on constrained hardware (Arduino, Raspberry Pi and similar), with a research-to-teaching loop that turns reference systems and benchmarks into curriculum. The repo organizes paths to read, build, explore, and deploy, and is maintained as a living resource with community contributions.</p>
<p>Students, instructors, researchers, and engineers who need practical, end‑to‑end expertise in building reliable, efficient AI systems benefit most—from classroom teaching to production and edge deployment. It’s trending because the community recognizes a gap between model-centered ML research and the systems engineering required to run models safely and efficiently in the real world, and this project offers open, hands‑on tooling and benchmarks that address that gap. The combination of a compact teaching framework (TinyTorch), reproducible benchmarks, hardware kits, and an active community makes it useful for training, curriculum development, and applied research.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>7. <a href="https://github.com/obra/superpowers" target="_blank" rel="noopener noreferrer">obra/superpowers</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">An agentic skills framework &amp; software development methodology that works.</p>
                    <p class="meta">
                        <span class="language">Shell</span> |
                        <span class="stars">54,629</span>
                        | <span class="today">868 stars today</span>
                    </p>
                    <p class="history">First seen: February 04, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Superpowers is a complete software development workflow for coding agents built around composable &quot;skills&quot; and starter instructions that make agents follow a consistent process. Key features include a modular skills library (TDD, systematic debugging, brainstorming, plan-writing, subagent-driven development, code review, and git worktree management), an enforced workflow that moves from spec elicitation to plan to task-level subagents, and a two-stage review system (spec compliance then code quality). Technically it ships as a plugin (Claude Code marketplace) with manual install paths for Codex and OpenCode, stores skills directly in the repository, and has agents fetch and execute skills, spawn subagents per task, and run automated verification and test-driven cycles. The repo also contains contribution guidance and update mechanics so skills can be extended and updated easily.</p>
<p>This project benefits developers, teams, and tool builders who want repeatable, evidence-driven AI-assisted engineering—especially those who need automated testing, clear task plans, and controlled parallel work via subagents. It’s gaining traction because it addresses practical pain points in agentic coding (avoiding ad-hoc behavior, enforcing RED‑GREEN‑REFACTOR, and integrating with git workflows) while offering an easy integration path for Claude Code and extensibility via an open-source MIT-licensed skill library.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>8. <a href="https://github.com/HailToDodongo/pyrite64" target="_blank" rel="noopener noreferrer">HailToDodongo/pyrite64</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">N64 Game-Engine and Editor using libdragon &amp; tiny3d</p>
                    <p class="meta">
                        <span class="language">C++</span> |
                        <span class="stars">1,393</span>
                        | <span class="today">419 stars today</span>
                    </p>
                    <p class="history">First seen: February 19, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Pyrite64 is an open-source Nintendo 64 game engine and editor that targets homebrew development by leveraging libdragon for hardware abstraction and tiny3d for low-level GPU rendering. The project bundles an in-console runtime with an editor and asset pipeline so creators can design scenes, manage resources, and build ROMs or run in emulators. Key features include a real-time 3D renderer, input and file I/O integration, and build scripts/tooling to cross-compile and package content for N64 hardware. Technically it ties together the N64 toolchain, libdragon APIs, and tiny3d primitives to deliver an integrated development workflow for the console.</p>
<p>This project benefits retro developers, hobbyists, educators, and anyone interested in creating or studying N64-era games because it lowers the barrier to producing and iterating on content for the console. It is trending in the homebrew and preservation communities due to renewed interest in retro platforms, improving cross-compile toolchains, and the appeal of a single repository that combines editor, engine, and deployment tools for rapid prototyping on real hardware or emulators.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>9. <a href="https://github.com/ComposioHQ/composio" target="_blank" rel="noopener noreferrer">ComposioHQ/composio</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Composio powers 1000+ toolkits, tool search, context management, authentication, and a sandboxed workbench to help you build AI agents that turn intent into action.</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">26,818</span>
                        | <span class="today">17 stars today</span>
                    </p>
                    <p class="history">First seen: February 19, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Composio is an SDK-driven platform for building AI agents that convert user intent into actions, providing TypeScript and Python clients, a sandboxed workbench, tool search, context management, and authentication. Key features include provider adapters (OpenAI, Anthropic, LangChain, Google Gemini, etc.), per-user tool and toolkit discovery, and Rube — a Model Context Protocol server that connects agents to 500+ apps (Gmail, Slack, GitHub, Notion). Technically, the SDKs are generated from an OpenAPI spec and communicate with the Composio backend to load toolsets, wire them into agent frameworks (e.g., OpenAI Agents, LangChain) via provider implementations, and manage sandboxing and invocation state. The system is extensible with custom providers and automated API spec pulls to keep SDKs and docs in sync.</p>
<p>Developers, AI product teams, and integrators building agentic workflows and automation will benefit most from Composio because it reduces plumbing effort around provider integration, authentication, context, and tool orchestration. By aggregating a large catalog of prebuilt toolkits and MCP integrations and offering sandboxing and provider-agnostic adapters, it accelerates prototyping and production deployment of action-oriented agents. Its OpenAPI-driven SDKs and multi-provider support align with the industry shift toward agent-first architectures and interoperability, which helps explain its traction among teams aiming to operationalize LLMs safely and quickly.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>10. <a href="https://github.com/p2r3/convert" target="_blank" rel="noopener noreferrer">p2r3/convert</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Truly universal online file converter</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">1,542</span>
                        | <span class="today">391 stars today</span>
                    </p>
                    <p class="history">First seen: February 19, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Convert.to.it is a web-based &quot;truly universal&quot; file converter that aims to handle cross‑medium conversions (e.g., converting videos to documents) rather than restricting operations to the same media type. It uses a modular TypeScript handler system (src/handlers and FormatHandler.ts) that normalizes tools and formats, enforces MIME normalization and buffer immutability, and lets each handler control output naming and conversion logic. The project is built for local development with Bun + Vite, supports adding npm or git submodule dependencies and WebAssembly binaries, and provides Docker Compose setups and a Puppeteer/Chromium cache build step to precompute supported-format lists for faster startup. Documentation and examples guide contributors through creating handlers and integrating external tools while keeping conversions composable and robust.</p>
<p>Privacy‑conscious users and power users who need unusual or cross‑media conversions benefit most, since the project emphasizes avoiding forced uploads to third‑party servers and supports self‑hosting. Developers and contributors also gain from a clear, extensible handler API, explicit contribution guidelines, and Dockerized/local development flows that lower the barrier to adding formats. The project has trended following a viral demo because of its ambitious &quot;convert anything&quot; promise, practical architecture for extensibility, and active issue/format-management practices that make it approachable for both users and maintainers.</p>
                    </div>
                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>

<script>
(() => {
    const readKey = "gtd:read_days:gh:v1";
    const dayStr = "2026-02-19";

    let stored = [];
    try {
        stored = JSON.parse(localStorage.getItem(readKey) || "[]");
        if (!Array.isArray(stored)) {
            stored = [];
        }
    } catch (_err) {
        stored = [];
    }

    if (!stored.includes(dayStr)) {
        stored.push(dayStr);
        stored.sort();
        localStorage.setItem(readKey, JSON.stringify(stored));
    }

    const collapseParam = new URLSearchParams(window.location.search).get("collapse_seen");
    const collapseSeen = collapseParam === "0" ? false : true;

    function setCollapsed(repoEl, collapsed) {
        repoEl.classList.toggle("collapsed", collapsed);
        const button = repoEl.querySelector(".repo-toggle");
        if (button) {
            button.textContent = collapsed ? "Show details" : "Hide details";
            button.setAttribute("aria-expanded", String(!collapsed));
        }
    }

    const repos = Array.from(document.querySelectorAll("section.repo[data-seen-before]"));

    repos.forEach((repoEl) => {
        const toggle = repoEl.querySelector(".repo-toggle");
        if (!toggle) {
            return;
        }

        toggle.addEventListener("click", () => {
            setCollapsed(repoEl, !repoEl.classList.contains("collapsed"));
        });
    });

    const collapseBtn = document.getElementById("collapse-seen-btn");
    const expandBtn = document.getElementById("expand-all-btn");

    if (collapseBtn) {
        collapseBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => {
                if (repoEl.dataset.seenBefore === "1") {
                    setCollapsed(repoEl, true);
                }
            });
        });
    }

    if (expandBtn) {
        expandBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => setCollapsed(repoEl, false));
        });
    }

    if (collapseSeen) {
        repos.forEach((repoEl) => {
            if (repoEl.dataset.seenBefore === "1") {
                setCollapsed(repoEl, true);
            }
        });
    }
})();
</script>

</body>
</html>
