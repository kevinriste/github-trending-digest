<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 04, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 04, 2026</h1>
        <nav>
            <a href="../">&larr; Back to Calendar</a>
        </nav>
    </header>
    <main>
        <article>
            <div class="repos">

            <section class="repo">
                <h3>1. <a href="https://github.com/thedotmack/claude-mem" target="_blank">thedotmack/claude-mem</a></h3>
                <p class="description">A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude&#x27;s agent-sdk), and injects relevant context back into future sessions.</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">20,818 stars</span>
                    | <span class="today">1,730 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Claude-Mem is a Claude Code plugin that automatically captures everything Claude does during coding sessions, compresses observations into semantic summaries using Claude&#x27;s agent-sdk, and injects relevant context into future sessions to preserve continuity. Key features include persistent memory across sessions, progressive-disclosure retrieval to save tokens, a mem-search skill (search/timeline/get_observations) for layered queries, a web viewer and HTTP worker on port 37777, and privacy controls to exclude sensitive content. Technically it uses lifecycle hooks to intercept session events, a Bun-managed worker service with a web UI, SQLite (with FTS5) for storage, and a Chroma vector store for hybrid semantic/keyword search; configuration lives in ~/.claude-mem and it requires Node.js/Bun and uv for vector search. The plugin is automatic once installed and exposes MCP tools so Claude can efficiently filter and fetch only the most relevant past observations.</p>
<p>This project is valuable to developers and teams who use Claude for multi-session projects, as it preserves institutional memory, speeds debugging and onboarding, and reduces prompt/token costs by filtering before fetching full details. Solo engineers, code reviewers, and long-running projects benefit from searchable, cited observations and a real-time memory stream to recall past decisions and tool outputs. It’s trending because it addresses a common pain point—ephemeral LLM session state—by combining agent-based summarization, vector search, and a plugin workflow that integrates directly into developer tools, improving productivity and continuity without manual note-taking.</p>

                </div>
            </section>

            <section class="repo">
                <h3>2. <a href="https://github.com/masoncl/review-prompts" target="_blank">masoncl/review-prompts</a></h3>
                <p class="description">AI review prompts</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">421 stars</span>
                    | <span class="today">54 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>This repository provides curated AI-assisted code review prompts and workflows tailored for Linux kernel and systemd development, designed to work with Claude Code and other AI tools. Its main features include project-specific skill files that auto-load context based on your working directory, slash commands for quick review/debug/verify actions (e.g., /kreview, /kdebug, /systemd-review), subsystem pattern documentation, and setup scripts to install prompts. Technically it packages skill templates, slash-command handlers, and subsystem files that supply domain-specific knowledge on demand, while detecting project roots to load relevant context. It also documents bug patterns and recommends pairing with semcode for fast semantic code navigation and search.</p>
<p>The project is valuable to kernel and systemd developers, maintainers, and reviewers who want consistent, repeatable AI-assisted review workflows to speed triage, debugging, and verification. Typical use cases include pre-commit or patchset reviews, focused debugging prompts for subsystem-specific issues, onboarding contributors to project conventions, and automated checks for common bug patterns. Its relevance is growing due to broader adoption of LLM-powered developer tooling and semantic search, which together improve review throughput and reduce manual effort in complex system codebases.</p>

                </div>
            </section>

            <section class="repo">
                <h3>3. <a href="https://github.com/openai/skills" target="_blank">openai/skills</a></h3>
                <p class="description">Skills Catalog for Codex</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">3,201 stars</span>
                    | <span class="today">377 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>This repository is a catalog of &quot;Agent Skills&quot;—self-contained folders of instructions, scripts, and resources that Codex-based AI agents can discover and use to perform specific tasks. Its main features include a folder-based open standard for packaging capabilities, separate channels for .system (auto-installed), curated, and experimental skills, and a $skill-installer that can install skills by name, folder, or GitHub URL; each skill carries its own LICENSE.txt for provenance and licensing. Technically, Codex loads installed skill directories at runtime so agents can invoke predefined workflows and assets, and administrators install or update skills via the installer and restart Codex to pick up changes.</p>
<p>This project is valuable for developers, AI teams, and product builders who need to rapidly compose repeatable agent behaviors and share capabilities across projects and organizations. It enables modularity and reuse—reducing duplicated work when creating automation, chat assistants, or task-specific agents—and supports experimentation by separating curated and experimental skill sets. Its relevance is growing because agent-based architectures and composable AI tooling are accelerating adoption, making standardized, discoverable skill packs a practical way to scale and govern agent capabilities.</p>

                </div>
            </section>

            <section class="repo">
                <h3>4. <a href="https://github.com/automazeio/ccpm" target="_blank">automazeio/ccpm</a></h3>
                <p class="description">Project management system for Claude Code using GitHub Issues and Git worktrees for parallel agent execution.</p>
                <p class="meta">
                    <span class="language">Shell</span> |
                    <span class="stars">6,784 stars</span>
                    | <span class="today">123 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Claude Code PM is a spec-driven project management system that converts PRDs into epics, decomposes epics into actionable tasks, and synchronizes those tasks with GitHub Issues while running multiple AI agents in parallel using Git worktrees. Its main features include a five‑phase discipline (brainstorm, document, plan, execute, track), a command set for creating and syncing PRDs/epics/issues (/pm:prd-new, /pm:epic-sync, /pm:issue-start, etc.), and a .claude workspace containing agents, commands, epics, and PRD files. Technically it treats GitHub Issues as the single source of truth and audit trail, uses worktrees to give independent agent branches and avoid conflicts, and updates progress via issue comments, labels, and PRs for full traceability.</p>
<p>This system is valuable for engineering teams, AI-augmented developers, and managers who need scalable, auditable collaboration between humans and LLM agents without losing context or creating merge conflicts. It speeds delivery by enabling parallel task execution, enforcing specification-first development to reduce rework and bugs, and providing transparent progress tracking in the GitHub ecosystem teams already use. Its relevance is rising with increased adoption of autonomous AI agents and the need for reproducible, Git-native workflows that integrate AI workstreams into existing team processes.</p>

                </div>
            </section>

            <section class="repo">
                <h3>5. <a href="https://github.com/obra/superpowers" target="_blank">obra/superpowers</a></h3>
                <p class="description">An agentic skills framework &amp; software development methodology that works.</p>
                <p class="meta">
                    <span class="language">Shell</span> |
                    <span class="stars">43,756 stars</span>
                    | <span class="today">817 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Superpowers is a workflow and skills library that turns LLM coding agents into structured software developers by providing composable &quot;skills&quot; and orchestrating instructions for design, planning, testing, and implementation. Its main features include Socratic brainstorming and design refinement, automated plan-writing that breaks work into bite-sized tasks, subagent-driven development with per-task dispatch and two-stage reviews, strict RED-GREEN-REFACTOR TDD, git worktree isolation, and pre/post-task review and finishing workflows. Technically it is distributed as platform-specific integrations (plugins or install instructions for Claude Code, Codex, and OpenCode) and organizes skills as modular files that trigger automatically to create isolated branches, run tests, dispatch subagents, and commit verified changes.</p>
<p>This framework is valuable for teams and solo developers who want repeatable, auditable AI-assisted development—especially where test-first discipline, code quality, and parallel tasking matter. It benefits engineering teams automating routine work, organizations adopting LLMs for coding, and researchers prototyping agent workflows by enforcing process (TDD, review) and reducing context drift via isolated worktrees and explicit plans. It’s gaining traction because broader LLM adoption creates demand for guardrails, composable automation, and reliable workflows that scale agentic behavior while maintaining code quality and reviewability.</p>

                </div>
            </section>

            <section class="repo">
                <h3>6. <a href="https://github.com/virattt/dexter" target="_blank">virattt/dexter</a></h3>
                <p class="description">An autonomous agent for deep financial research</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">10,185 stars</span>
                    | <span class="today">222 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Dexter is an autonomous financial research agent that decomposes complex questions into step-by-step research plans, executes domain-specific tools to gather real-time financial data, and iterates via self-reflection to produce confident, data-backed answers. Technically it runs on the Bun runtime, orchestrates LLM providers (OpenAI, Anthropic, etc.), and integrates with Financial Datasets and web-search APIs (Exa/Tavily) to pull income statements, balance sheets, and cash flow data. The agent logs every tool call and internal reasoning to newline-delimited JSON scratchpads (.dexter/scratchpad/) for debugging and provenance, and includes safety features like loop detection and step limits.</p>
<p>This project is useful for buy-side and sell-side analysts, quant researchers, fintech engineers, and educators who need faster, repeatable financial research, model validation, or batch evaluation of research questions. Typical use cases include automated due diligence, earnings and trend analysis, hypothesis testing across securities, and running eval suites with LangSmith-backed LLM-as-judge scoring. Its audit-ready logs, extensible toolset, and real-time data integration make it a practical, reproducible research assistant and a timely open-source example of specialized autonomous agents in the modern LLM ecosystem.</p>

                </div>
            </section>

            <section class="repo">
                <h3>7. <a href="https://github.com/karpathy/nanochat" target="_blank">karpathy/nanochat</a></h3>
                <p class="description">The best ChatGPT that $100 can buy.</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">42,095 stars</span>
                    | <span class="today">447 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>nanochat is a compact, hackable PyTorch harness for training, evaluating, and interacting with transformer LLMs on a single GPU node or small multi‑GPU setups. It bundles tokenization (BPE), data loading, the GPT model implementation, optimizer (AdamW + Muon), distributed training utilities, evaluation (CORE metric, bits‑per‑byte), KV‑cache inference engine, checkpoint management, and a ChatGPT‑like web UI; the repo includes runnable scripts (e.g., runs/speedrun.sh) that automate end‑to‑end pretraining and finetuning workflows using torchrun, gradient accumulation, and optional wandb logging. The code is intentionally minimal so users can reproduce GPT‑2‑grade models quickly (targeting an 8×H100 node in ~3 hours) and experiment with scaling laws, synthetic data, or custom SFT stages. It also provides support for CPU/MPS, small‑model quick experiments, and a leaderboard/metrics to compare runs.</p>
<p>This project is valuable for researchers, engineers, educators, and hobbyists who want an accessible, reproducible platform to prototype and study LLM training and finetuning without a large infrastructure investment. It enables rapid iteration on model depth, data budgets, and training recipes, making it useful for scaling‑law research, model development, and building custom chatbots or fine‑tuned assistants. nanochat is trending because it dramatically lowers the barrier to entry for training capable LLMs (cost/time reductions), offers a concise codebase that’s easy to modify, and provides community hooks (Discussions/Discord/leaderboard) for collaborative experimentation.</p>

                </div>
            </section>

            <section class="repo">
                <h3>8. <a href="https://github.com/kovidgoyal/calibre" target="_blank">kovidgoyal/calibre</a></h3>
                <p class="description">The official source code repository for the calibre ebook manager</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">23,949 stars</span>
                    | <span class="today">141 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Calibre is an open-source e-book manager that lets users view, convert, edit, and catalog e-books in all major formats, sync with e-reader devices, fetch metadata from the internet, and convert news into e-book form. The repository contains the application source and build instructions for producing platform-specific binaries for Linux, Windows and macOS. Technically it combines a desktop GUI with a conversion/processing engine, device communication drivers, internet metadata/news fetchers and a content server, and exposes extensibility via plugins. The core application is implemented to be portable across platforms (commonly using Python and cross-platform GUI libraries) and includes tooling for building installers.</p>
<p>The project is valuable to individual readers, e-reader owners, librarians, archivists and developers who need a single, flexible tool to manage large digital book collections and to interoperate across devices and formats. It centralizes library organization, automated metadata enrichment, format conversion and device synchronization, reducing friction when moving books between ecosystems. Its open-source nature, extensibility and active maintenance make it a practical choice for users who want control, automation and long-term access to their e-book collections, which helps explain its ongoing popularity.</p>

                </div>
            </section>

            <section class="repo">
                <h3>9. <a href="https://github.com/OpenBMB/ChatDev" target="_blank">OpenBMB/ChatDev</a></h3>
                <p class="description">ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration</p>
                <p class="meta">
                    <span class="language">Python</span> |
                    <span class="stars">29,823 stars</span>
                    | <span class="today">476 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>ChatDev 2.0 (DevAll) is a zero-code multi-agent orchestration platform that enables users to design, configure, and execute custom multi-agent systems via a visual workflow canvas or YAML configurations. It provides a web console and a Python SDK for programmatic runs, and orchestrates LLM-powered agents organized in chain or DAG topologies (MacNet) to perform complex tasks while logging intermediate artifacts and supporting human-in-the-loop feedback. The codebase implements multiple orchestration paradigms—including the original ChatDev virtual software company, MacNet for scalable DAG collaboration, and a puppeteer-style learnable central orchestrator trained with reinforcement learning to dynamically activate and sequence agents—and incorporates techniques like Iterative Experience Refinement and Experiential Co-Learning. The stack uses a Python backend and a Vite/Vue frontend, with model keys and runtime settings supplied via .env or YAML placeholders, plus options for Docker, Git integration, and incremental development.</p>
<p>This project is valuable for developers, researchers, and product teams who need to automate complex, multi-step workflows—ranging from end-to-end software development to data visualization, 3D generation, research assistance, and content creation—without writing orchestration code. It supports rapid prototyping, reproducible experiments, and scalable agent collaboration (the MacNet design claims support for thousands of agents) while reducing compute and improving reasoning quality via learned orchestration, making it appealing for teams optimizing cost and performance. Its open-source research pedigree (published preprints and a NeurIPS-accepted paper), combined with no-code tooling, human-in-the-loop modes, and integrations for common developer workflows, help explain its traction in the LLM multi-agent community.</p>

                </div>
            </section>

            <section class="repo">
                <h3>10. <a href="https://github.com/pedramamini/Maestro" target="_blank">pedramamini/Maestro</a></h3>
                <p class="description">Agent Orchestration Command Center</p>
                <p class="meta">
                    <span class="language">TypeScript</span> |
                    <span class="stars">1,537 stars</span>
                    | <span class="today">269 stars today</span>
                </p>
                <div class="ai-summary">
                    <h4>Analysis</h4>
                    <p>Maestro is a cross-platform desktop application that orchestrates fleets of AI agents and automates project workflows, enabling users to run many isolated agent sessions in parallel and batch-process tasks via Auto Run and playbooks. Its main features include Git worktrees for per-agent isolated branches, file-system-based playbooks that turn markdown checklists into fresh AI sessions, group chat with a moderator AI, session discovery across supported providers, a CLI for headless operation, and a built-in web server for mobile remote control. Technically it’s an Electron/Node-based app (buildable with npm) that integrates with agent CLIs/APIs (Claude Code, OpenAI Codex, OpenCode, Factory Droid), manages per-agent workspaces and conversation histories, hooks into git for branch-aware tooling, and exposes JSONL-friendly outputs and queuing for automation and CI.</p>
<p>Maestro is valuable for developers, AI researchers, and power users who need to coordinate multiple agent-driven coding tasks, run long unattended sessions, or create repeatable agent workflows across projects. It accelerates parallel development by isolating agent workspaces with Git worktrees, automating routine work with playbooks, and providing analytics, cost tracking, and a keyboard-first UX geared toward high-velocity workflows. Given the current momentum around agent orchestration and agentic automation, Maestro is well suited to solo hackers, small teams, and organizations experimenting with integrating multiple coding agents, CI/CD pipelines, and remote control into their development process.</p>

                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>
</body>
</html>
