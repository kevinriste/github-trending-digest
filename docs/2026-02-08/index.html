<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 08, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 08, 2026</h1>
        <nav>
            <a href="../">&larr; GitHub Calendar</a>
            <a href="../hn/">Hacker News</a>
        </nav>
    </header>
    <main>
        <div class="repo-controls">
            <button id="collapse-seen-btn" type="button">Collapse Repos Not New Today</button>
            <button id="expand-all-btn" type="button">Expand All</button>
        </div>
        <p class="seen-help">Repos marked "Not new today" appeared on one or more previous daily pages.</p>
        <article>
            <div class="repos">

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>1. <a href="https://github.com/KeygraphHQ/shannon" target="_blank" rel="noopener noreferrer">KeygraphHQ/shannon</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Fully autonomous AI hacker to find actual exploits in your web apps. Shannon has achieved a 96.15% success rate on the hint-free, source-aware XBOW Benchmark.</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">10,494 stars</span>
                        | <span class="today">3,139 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Shannon is an autonomous AI pentester that analyzes a target application&#x27;s source code and then autonomously hunts for and executes real-world exploits using a built-in browser and command-line actions to produce reproducible proof-of-concept attacks. Its main features include detection and validation of critical OWASP vulnerabilities (injection, XSS, SSRF, broken auth/authorization), code-aware dynamic testing, parallelized workflows, and integrations with reconnaissance/testing tools such as Nmap, Subfinder, WhatWeb, and Schemathesis. Technically it runs as containerized workflows (Docker), leverages an LLM provider (Anthropic or Claude) to drive decision-making, and exposes monitoring via a workflow UI while emitting pentester-grade reports with copy-and-paste PoCs. This repository contains Shannon Lite (AGPL-3.0) for white-box source-available testing; a commercial Pro edition adds deeper LLM-powered data-flow analysis and enterprise integrations.</p>
<p>Shannon delivers clear value to security teams, DevOps, and independent researchers who need on-demand, reproducible penetration testing to close the gap between rapid shipping and infrequent manual pentests, because it verifies exploitable issues rather than just flagging potential vulnerabilities. Itâ€™s well suited for organizations that can provide source repositories and want continuous testing or CI/CD and compliance automation (e.g., SOC 2/HIPAA evidence collection), and for red teams that need scalable, repeatable attack validation. The project is gaining attention because it combines modern LLM orchestration with established security tooling to accelerate exploit discovery, reduce false positives through validated PoCs, and lower the operational cost of frequent security validation. Small teams can experiment with the AGPL Lite, while enterprises benefit from the Pro editionâ€™s advanced analysis and support.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>2. <a href="https://github.com/openai/skills" target="_blank" rel="noopener noreferrer">openai/skills</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Skills Catalog for Codex</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">6,253 stars</span>
                        | <span class="today">592 stars today</span>
                    </p>
                    <p class="history">First seen: February 04, 2026 | Consecutive daily streak: 5 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository catalogs &quot;Agent Skills&quot;â€”self-contained folders of instructions, scripts, and resources that Codex-based AI agents can discover and use to perform specific tasks. Its main features include a curated and experimental skills layout, automatic installation of .system skills, and a $skill-installer command that adds skills by name, folder, or GitHub directory URL; each skill carries its own LICENSE.txt and follows the Agent Skills open standard. Technically, skills are packaged as directory-based modules that Codex imports at runtime (requiring a restart to pick up new skills), enabling repeatable, shareable capabilities composed of prompts, scripts, and ancillary assets. The repository therefore acts as both a registry and distribution mechanism for modular agent behaviors.</p>
<p>The project is valuable to developers, product teams, and organizations building agent-driven automation because it centralizes reusable, testable components that speed development and reduce duplication of effort. Use cases include domain-specific automation, standardized prompt and workflow sharing, rapid prototyping of agent capabilities, and collaboration across teams that need consistent agent behavior. Itâ€™s gaining traction because modular, discoverable skills align with the broader trend toward agentization and platformization of AI tooling, making it easier to scale and govern autonomous workflows.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>3. <a href="https://github.com/microsoft/litebox" target="_blank" rel="noopener noreferrer">microsoft/litebox</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A security-focused library OS supporting kernel- and user-mode execution</p>
                    <p class="meta">
                        <span class="language">Rust</span> |
                        <span class="stars">1,193 stars</span>
                        | <span class="today">584 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>LiteBox is a sandboxing library OS that minimizes the host interface to reduce attack surface while enabling both kernel- and user-mode execution. It provides a Rust-y, nix/rustix-inspired &quot;North&quot; API that is paired with pluggable &quot;South&quot; Platform backends, allowing a wide variety of Northâ€“South combinations and easy interoperation of shims and platforms. Technically, the project is modular: the North surface exposes POSIX-like primitives to runtimes and applications, and the South adapters implement those primitives against different hosts (Windows, Linux, SEV SNP, OP-TEE, LVBS, etc.), enabling unmodified binaries or constrained workloads to run across environments.</p>
<p>The project is valuable for security-focused system and platform developers, cloud and virtualization engineers, and anyone needing portable sandboxing or compatibility layers (for example, running Linux programs on Windows or isolating Linux workloads). Its pluggable architecture and focus on minimizing host interfaces make it attractive for mitigating attack surface in sensitive deployments, integrating with enclave technologies, and experimenting with alternative runtime models. Growing interest in Rust-based systems, supply-chain security, and hardware-backed isolation helps explain why a flexible library OS like LiteBox is gaining attention.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>4. <a href="https://github.com/p-e-w/heretic" target="_blank" rel="noopener noreferrer">p-e-w/heretic</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Fully automatic censorship removal for language models</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">4,787 stars</span>
                        | <span class="today">69 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Heretic is a tool for automatically removing censorship (safety alignment) from transformer-based language models by applying directional ablation (aka &quot;abliteration&quot;) combined with a TPE-based parameter optimizer implemented with Optuna. The system automatically searches for abliteration parameters that co-minimize the number of refusals on &quot;harmful&quot; prompts and the KL divergence from the original model on &quot;harmless&quot; prompts, producing decensored models that retain as much capability as possible without costly post-training. It supports most dense and many multimodal and MoE architectures, includes bitsandbytes quantization to reduce VRAM requirements, and provides built-in benchmarking, evaluation, saving/uploading to Hugging Face, and an interactive test/chat option. Optional research features expose interpretability tooling such as PaCMAP projections of residuals, residual-geometry metrics, layer-wise plots, and animations to study how harmful/harmless signals evolve through the network.</p>
<p>Heretic benefits researchers and engineers who want to study or deploy models with fewer safety refusals while preserving original capabilities, as well as hobbyists and operators constrained by GPU memory who can leverage quantization and automatic configuration. It is trending because it automates a previously expert-driven process, reporting abliterations that match or outperform manual efforts on refusal suppression with lower KL damage, and because community-shared decensored models and positive user feedback have driven visibility. Its combination of practical usability, research-focused diagnostics, and competitive empirical results makes it attractive to both the interpretability community and practitioners seeking controllable model behavior.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>5. <a href="https://github.com/obra/superpowers" target="_blank" rel="noopener noreferrer">obra/superpowers</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">An agentic skills framework &amp; software development methodology that works.</p>
                    <p class="meta">
                        <span class="language">Shell</span> |
                        <span class="stars">47,132 stars</span>
                        | <span class="today">686 stars today</span>
                    </p>
                    <p class="history">First seen: February 04, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Superpowers is a complete software development workflow for coding agents built around composable &quot;skills&quot; and starter instructions that make agents follow a consistent process. Key features include a modular skills library (TDD, systematic debugging, brainstorming, plan-writing, subagent-driven development, code review, and git worktree management), an enforced workflow that moves from spec elicitation to plan to task-level subagents, and a two-stage review system (spec compliance then code quality). Technically it ships as a plugin (Claude Code marketplace) with manual install paths for Codex and OpenCode, stores skills directly in the repository, and has agents fetch and execute skills, spawn subagents per task, and run automated verification and test-driven cycles. The repo also contains contribution guidance and update mechanics so skills can be extended and updated easily.</p>
<p>This project benefits developers, teams, and tool builders who want repeatable, evidence-driven AI-assisted engineeringâ€”especially those who need automated testing, clear task plans, and controlled parallel work via subagents. Itâ€™s gaining traction because it addresses practical pain points in agentic coding (avoiding ad-hoc behavior, enforcing REDâ€‘GREENâ€‘REFACTOR, and integrating with git workflows) while offering an easy integration path for Claude Code and extensibility via an open-source MIT-licensed skill library.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>6. <a href="https://github.com/OpenBMB/MiniCPM-o" target="_blank" rel="noopener noreferrer">OpenBMB/MiniCPM-o</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A Gemini 2.5 Flash Level MLLM for Vision, Speech, and Full-Duplex Multimodal Live Streaming on Your Phone</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">23,201 stars</span>
                        | <span class="today">44 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>MiniCPM-o is an open-source series of onâ€‘device multimodal large language models (MLLMs) that take images, video, text, and audio as inputs and produce highâ€‘quality text and speech outputs end-to-end. The flagship MiniCPM-o 4.5 (~9B parameters) and the efficient MiniCPMâ€‘V 4.0 (~4B) introduce fullâ€‘duplex multimodal live streamingâ€”simultaneous realâ€‘time input (video/audio) and output (speech/text)â€”along with bilingual realâ€‘time voice, voice cloning, OCR, and multilingual understanding. Technically the project provides optimized model weights plus inference tooling and demos (gguf/llama.cppâ€‘omni, vLLM, Ollama integrations, WebRTC demo) and an official Docker image for local, lowâ€‘latency deployment on phones and Macs. It also supplies alignment and fineâ€‘tuning pipelines (e.g., RLAIFâ€‘V) and supports quantized and multiâ€‘framework workflows for efficient onâ€‘device inference.</p>
<p>The project is useful to developers, researchers, and product teams building privacyâ€‘sensitive, lowâ€‘latency multimodal assistants, AR/VR interactions, realâ€‘time customer service agents, and accessibility tools that require simultaneous vision and speech understanding and generation. Because the models claim parity with highâ€‘end commercial systems while remaining small enough for local deployment, teams can prototype and ship interactive experiences without heavy cloud dependency. The extensive tooling, demos, and cookbook lower the integration and fineâ€‘tuning barrier for the openâ€‘source community. Its combination of strong multimodal capability, efficient inference, and active ecosystem support explains why it has gained traction and trending attention.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>7. <a href="https://github.com/aquasecurity/trivy" target="_blank" rel="noopener noreferrer">aquasecurity/trivy</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
                    <p class="meta">
                        <span class="language">Go</span> |
                        <span class="stars">31,709 stars</span>
                        | <span class="today">168 stars today</span>
                    </p>
                    <p class="history">First seen: February 06, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Trivy is a comprehensive security scanner that detects vulnerabilities, misconfigurations, secrets and produces SBOMs across container images, filesystems, Git repositories, VM images and Kubernetes clusters. It bundles multiple scanners for OS packages and language dependencies, known CVEs, IaC misconfigurations, secret detection and license checks, and supports most popular languages, OSes and platforms. Technically, Trivy is a Go-based CLI and library that inspects artifacts directly (image layers, files, git trees, k8s API), consults vulnerability and SBOM data sources, and emits reports in multiple formats. It runs as a standalone binary or container, integrates with CI/CD and ecosystem tools (GitHub Actions, k8s operator, VS Code), and provides canary builds for rapid iteration.</p>
<p>Trivy is valuable to developers, DevSecOps and security teams who need fast, automated detection of security issues across the software supply chain. Typical use cases include shift-left scanning in CI pipelines, pre-deployment Kubernetes audits, image/VM hardening, repository secret detection and SBOM generation for compliance. Its broad coverage, ease of installation and integration, and active open-source maintenance by Aqua make it attractive for organizations prioritizing supply-chain security. The project is trending because it delivers pragmatic, multi-target scanning and policy-driven automation that fits modern cloud-native workflows.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>8. <a href="https://github.com/wavetermdev/waveterm" target="_blank" rel="noopener noreferrer">wavetermdev/waveterm</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">An open-source, cross-platform terminal for seamless workflows</p>
                    <p class="meta">
                        <span class="language">Go</span> |
                        <span class="stars">17,170 stars</span>
                        | <span class="today">25 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Wave is an open-source, cross-platform terminal that blends a traditional CLI with graphical capabilities like file previews, embedded web browsing, a built-in editor, and an AI assistant. It exposes a draggable multi-block workspace containing terminals, editors, preview widgets and AI chat panels, plus features such as command blocks, one-click SSH/remote connections, secure native secret storage, and connected file management (including Wave filesystem and S3). Technically it runs on macOS, Linux and Windows, uses a WSH helper and the wsh CLI to manage workspaces and share data across sessions, and integrates multiple AI providers (OpenAI, Claude, Azure, Perplexity, Ollama) so Wave AI can read terminal context, suggest edits, and perform file operations with user approval. Customization, theming, and scripting via wsh let users automate workflows and persist or share workspace state.</p>
<p>Wave is valuable to developers, sysadmins, DevOps engineers, and remote teams who frequently switch between terminals and graphical tools, because it reduces context switching by consolidating previews, documentation, remote file editing, and AI assistance into a single environment. It speeds debugging, file manipulation, and monitoring workflows while simplifying remote access and synchronized file transfers across hosts. The integrated AI assistant and extensible CLI tooling make Wave appealing for teams seeking assisted coding, reproducible workflows, and automation, and its open-source, cross-platform design with multiple AI provider options helps explain its growing adoption.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>9. <a href="https://github.com/viarotel-org/escrcpy" target="_blank" rel="noopener noreferrer">viarotel-org/escrcpy</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">ðŸ“± Display and control your Android device graphically with scrcpy.</p>
                    <p class="meta">
                        <span class="language">JavaScript</span> |
                        <span class="stars">7,884 stars</span>
                        | <span class="today">27 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Escrcpy is a graphical tool for displaying and controlling Android devices that extends the popular scrcpy screen-mirroring core with a polished Electron/Vue GUI and added automation. Its main features include natural-language intelligent control via AutoGLM, automated workflows with parallel multi-device execution, window orchestration for managing several devices, and wireless connectivity including Gnirehtet reverse tethering. Technically it combines scrcpy for low-latency mirroring, adbkit for ADB interactions, autoglm.js for language-driven commands, and Electron/Vue for the cross-platform desktop interface, with packaged releases and a Homebrew tap for macOS.</p>
<p>This project is valuable for mobile developers, QA engineers, support teams, and anyone who needs centralized control or automated testing across multiple Android devices because it simplifies remote interaction, scripting, and parallel device orchestration. The addition of natural-language control and reverse-tethering support makes it useful for automation-driven workflows, demos, and networks where devices lack direct internet access. Its momentum comes from building on well-known open-source components (scrcpy, adbkit, gnirehtet) while adding convenience features and a GUI that address common multi-device and automation pain points.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>10. <a href="https://github.com/ComposioHQ/awesome-claude-skills" target="_blank" rel="noopener noreferrer">ComposioHQ/awesome-claude-skills</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A curated list of awesome Claude Skills, resources, and tools for customizing Claude AI workflows</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">32,160 stars</span>
                        | <span class="today">443 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a curated collection of Claude Skillsâ€”reusable, customizable workflows and tools for Claude.ai, Claude Code, and the Claude APIâ€”grouped by categories like document processing, development &amp; code tools, data &amp; analysis, business &amp; marketing, and more. It bundles ready-made skills (e.g., PDF/DOCX/XLSX handlers, Playwright browser automation, changelog generation, CSV summarizers, Postgres query tooling) and integration helpers such as the Composio connect-apps plugin that links Claude to 500+ or 1000+ external apps. Technically, skills are implemented as model-invoked workflows and plugins that teach Claude task-specific behaviors and, when installed (for example via claude --plugin-dir and /connect-apps:setup), let the assistant perform real actions by handling auth and API calls through Composio. The repo also includes guidance for creating new skills, developer-focused tooling, and community-contributed recipes to extend Claudeâ€™s capabilities.</p>
<p>The project is valuable to developers, product teams, data analysts, content creators, and ops/security engineers who want to standardize and automate work with an LLM that can take actions beyond text generationâ€”sending emails, creating issues, posting to Slack, running tests, extracting data, and more. It accelerates workflows by providing off-the-shelf, tested patterns and connectors that bridge Claude to databases, CI, cloud services, and SaaS apps, reducing engineering overhead to build integrations from scratch. Its popularity is driven by growing demand for agentic, action-capable AI, broad app connectivity via Composio, and an active community contributing domain-specific skills that make deployment and iteration fast and practical.</p>
                    </div>
                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>

<script>
(() => {
    const readKey = "gtd:read_days:gh:v1";
    const dayStr = "2026-02-08";

    let stored = [];
    try {
        stored = JSON.parse(localStorage.getItem(readKey) || "[]");
        if (!Array.isArray(stored)) {
            stored = [];
        }
    } catch (_err) {
        stored = [];
    }

    if (!stored.includes(dayStr)) {
        stored.push(dayStr);
        stored.sort();
        localStorage.setItem(readKey, JSON.stringify(stored));
    }

    const collapseParam = new URLSearchParams(window.location.search).get("collapse_seen");
    const collapseSeen = collapseParam === "0" ? false : true;

    function setCollapsed(repoEl, collapsed) {
        repoEl.classList.toggle("collapsed", collapsed);
        const button = repoEl.querySelector(".repo-toggle");
        if (button) {
            button.textContent = collapsed ? "Show details" : "Hide details";
            button.setAttribute("aria-expanded", String(!collapsed));
        }
    }

    const repos = Array.from(document.querySelectorAll("section.repo[data-seen-before]"));

    repos.forEach((repoEl) => {
        const toggle = repoEl.querySelector(".repo-toggle");
        if (!toggle) {
            return;
        }

        toggle.addEventListener("click", () => {
            setCollapsed(repoEl, !repoEl.classList.contains("collapsed"));
        });
    });

    const collapseBtn = document.getElementById("collapse-seen-btn");
    const expandBtn = document.getElementById("expand-all-btn");

    if (collapseBtn) {
        collapseBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => {
                if (repoEl.dataset.seenBefore === "1") {
                    setCollapsed(repoEl, true);
                }
            });
        });
    }

    if (expandBtn) {
        expandBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => setCollapsed(repoEl, false));
        });
    }

    if (collapseSeen) {
        repos.forEach((repoEl) => {
            if (repoEl.dataset.seenBefore === "1") {
                setCollapsed(repoEl, true);
            }
        });
    }
})();
</script>

</body>
</html>
