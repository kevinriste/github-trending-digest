<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 25, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 25, 2026</h1>
        <nav>
            <a href="../">&larr; GitHub Calendar</a>
            <a href="../hn/2026-02-25/">Hacker News</a>
        </nav>
    </header>
    <main>
        <div class="repo-controls">
            <button id="collapse-seen-btn" type="button">Collapse Repos Not New Today</button>
            <button id="expand-all-btn" type="button">Expand All</button>
        </div>
        <p class="seen-help">Repos marked "Not new today" appeared on one or more previous daily pages.</p>
        <article>
            <div class="repos">

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>1. <a href="https://github.com/huggingface/skills" target="_blank" rel="noopener noreferrer">huggingface/skills</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">No description</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">5,662</span>
                        | <span class="today">1,206 stars today</span>
                    </p>
                    <p class="history">First seen: February 22, 2026 | Consecutive daily streak: 4 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository defines &quot;skills&quot;: self-contained folders that package instructions (SKILL.md with YAML frontmatter), scripts, templates, and resources so coding agents can perform common AI/ML tasks such as dataset creation, model training, evaluation, job management, and more. It includes ready-made skills (hf CLI, datasets, evaluation, jobs, model trainer, paper publisher, tool builder, Trackio) and provides installation/manifest support for multiple agent ecosystems (Claude/Claude Code, OpenAI Codex, Google Gemini CLI, Cursor) via AGENTS.md, gemini-extension.json, and Cursor plugin files. Technically, skills are interoperable artifacts that agents load to obtain step-by-step guidance and helper tooling; the repo also provides scripts to publish/regenerate manifests and CI checks to validate metadata and marketplace listings. The result is a standardized, reusable package format that lets agents orchestrate local or Hugging Face cloud workflows reliably.</p>
<p>This project is useful for ML engineers, MLOps teams, researchers, and developers who want to automate common model and dataset workflows through coding agents and the Hugging Face platform. It reduces manual orchestration, improves reproducibility, and makes it easy to share and extend operational patterns as installable agent plugins. Its momentum comes from the growing adoption of LLM-driven coding agents, the need for cross-platform interoperability, and tight integration with Hugging Face&#x27;s tooling and cloud compute, which together lower friction for running end-to-end ML tasks.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>2. <a href="https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering" target="_blank" rel="noopener noreferrer">muratcankoylan/Agent-Skills-for-Context-Engineering</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">10,143</span>
                        | <span class="today">722 stars today</span>
                    </p>
                    <p class="history">First seen: February 24, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a curated collection of &quot;Agent Skills&quot; for context engineering that codifies practical patterns, tools, and examples to manage the information fed into LLM-based agents. Key features include foundational material on context mechanics and degradation, architectural modules for multi-agent patterns, memory systems, tool and filesystem integration, operational modules for compression/optimization and evaluation, and cognitive BDI mental-state transformations. Technically, skills are packaged as platform-agnostic modules (Claude Code marketplace plugins, Cursor/Codex/IDE rules or standalone skill files), use progressive disclosure so full skill content loads only when activated, and ship Python-pseudocode, triggers, and installation commands that let agent runtimes discover and apply relevant skills at runtime. The repo also documents attention-aware tactics (compaction, masking, caching), LLM-as-judge evaluation methods, and hosted-agent designs for sandboxed background execution.</p>
<p>This project benefits AI engineers, multi-agent architects, ops teams, and researchers who need repeatable, production-grade patterns for conserving model attention and debugging context failures. It accelerates development by turning abstract attention mechanics into actionable skills, templates, and plugin workflows that integrate with existing agent platforms. The collection is timely and trending because managing limited context windows is a growing practical bottleneck as agentic systems scale, and because the work has received academic recognition for helping bridge manual skill engineering and dynamic evolution of agent skills.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>3. <a href="https://github.com/OpenBB-finance/OpenBB" target="_blank" rel="noopener noreferrer">OpenBB-finance/OpenBB</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Financial data platform for analysts, quants and AI agents.</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">61,980</span>
                        | <span class="today">504 stars today</span>
                    </p>
                    <p class="history">First seen: February 23, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Open Data Platform (ODP) by OpenBB is an open-source toolset that consolidates proprietary, licensed, and public financial data and exposes it to multiple downstream surfaces such as Python environments for quants, OpenBB Workspace and Excel for analysts, MCP servers for AI agents, and REST APIs for other applications. Key features include a Python SDK (pip install openbb), a CLI, extensive data integrations, AI-agent support, and enterprise UI integration for visual workflows, all built around a ‚Äúconnect once, consume everywhere‚Äù philosophy. Technically it can run as a local backend (openbb-api) using FastAPI and Uvicorn (default on 127.0.0.1:6900) or be used directly as a library, enabling SDK calls, REST access, and easy integration into downstream systems. The project is community-driven, documented on GitHub, and distributed under AGPLv3.</p>
<p>The platform is valuable for data engineers, analysts, quants, AI/ML teams, fintech firms, and researchers who need to ingest, normalize, and serve heterogeneous financial datasets into analytics, dashboards, or AI agents. It‚Äôs trending because it combines open-source accessibility, broad connector coverage, and a Python-first developer experience with an enterprise UI, making it straightforward to prototype, deploy, and scale data-driven financial products and AI copilots. Active community contributions, simple local deployment, and explicit support for agent and workspace integrations further accelerate adoption.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>4. <a href="https://github.com/LadybirdBrowser/ladybird" target="_blank" rel="noopener noreferrer">LadybirdBrowser/ladybird</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Truly independent web browser</p>
                    <p class="meta">
                        <span class="language">C++</span> |
                        <span class="stars">59,184</span>
                        | <span class="today">236 stars today</span>
                    </p>
                    <p class="history">First seen: February 25, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Ladybird is a truly independent web browser implementing a novel engine based on web standards and currently in a pre-alpha state. It employs a multi-process architecture with a main UI process, per-tab sandboxed WebContent renderer processes, and dedicated ImageDecoder and RequestServer processes so that image decoding and network I/O occur out-of-process for increased robustness against malicious content. The codebase reuses many SerenityOS libraries (LibWeb, LibJS, LibWasm, LibCrypto/LibTLS, LibHTTP, LibGfx, LibMedia, LibCore, LibIPC, etc.) to provide rendering, scripting, networking, graphics, media, and IPC, and it builds on Linux, macOS, Windows (via WSL2) and other Unix-like systems.</p>
<p>Developers, browser engineers, security researchers, and contributors who want an open, standards-focused alternative to major engines will benefit from Ladybird because it provides a clear, modular codebase designed for experimentation and hardening. Its emphasis on sandboxing and out-of-process handling of risky subsystems, combined with active community channels and contribution guidelines, makes it useful for security testing, education, and prototyping new browser features. The project is drawing attention as a lightweight, independent approach to modern browser design and as a practical platform for exploring standards-compliant engine development.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>5. <a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools" target="_blank" rel="noopener noreferrer">x1xhlol/system-prompts-and-models-of-ai-tools</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, Dia &amp; v0. (And other Open Sourced) System Prompts, Internal Tools &amp; AI Models</p>
                    <p class="meta">
                        <span class="language">Unknown</span> |
                        <span class="stars">123,292</span>
                        | <span class="today">3,804 stars today</span>
                    </p>
                    <p class="history">First seen: February 23, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a large, curated collection of system prompts, internal tool instructions, and model configuration examples for a wide range of AI products (e.g., Claude Code, Comet, Replit, NotionAI, Perplexity and many others). Key features include more than 30k lines of prompts and templates, organized examples per product, and a README with contribution and support information. Technically the content is stored as plain-text prompt files, JSON/YAML or code snippets and organized into folders by tool so users can inspect, copy, and adapt configurations for experimentation or integration. The project is maintained via standard GitHub workflows (issues, updates, and a roadmap) and is intended to be searchable and extensible by contributors.</p>
<p>This collection benefits prompt engineers, AI developers, integration teams, security auditors, and researchers who need ready-made prompts, model tuning examples, and insight into real-world tool behaviors. It speeds prototyping by providing copy/pasteable templates and documented configurations that illustrate how different models and agents are instructed. The repository is trending because of rising interest in prompt engineering, reproducibility of AI behaviors, and the need for transparent examples for building, evaluating, and securing AI-driven products. Its breadth and community-oriented format make it a convenient reference for both practitioners and auditors.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>6. <a href="https://github.com/obra/superpowers" target="_blank" rel="noopener noreferrer">obra/superpowers</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">An agentic skills framework &amp; software development methodology that works.</p>
                    <p class="meta">
                        <span class="language">Shell</span> |
                        <span class="stars">60,752</span>
                        | <span class="today">1,195 stars today</span>
                    </p>
                    <p class="history">First seen: February 04, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Superpowers is a complete software development workflow for coding agents built around composable &quot;skills&quot; and starter instructions that make agents follow a consistent process. Key features include a modular skills library (TDD, systematic debugging, brainstorming, plan-writing, subagent-driven development, code review, and git worktree management), an enforced workflow that moves from spec elicitation to plan to task-level subagents, and a two-stage review system (spec compliance then code quality). Technically it ships as a plugin (Claude Code marketplace) with manual install paths for Codex and OpenCode, stores skills directly in the repository, and has agents fetch and execute skills, spawn subagents per task, and run automated verification and test-driven cycles. The repo also contains contribution guidance and update mechanics so skills can be extended and updated easily.</p>
<p>This project benefits developers, teams, and tool builders who want repeatable, evidence-driven AI-assisted engineering‚Äîespecially those who need automated testing, clear task plans, and controlled parallel work via subagents. It‚Äôs gaining traction because it addresses practical pain points in agentic coding (avoiding ad-hoc behavior, enforcing RED‚ÄëGREEN‚ÄëREFACTOR, and integrating with git workflows) while offering an easy integration path for Claude Code and extensibility via an open-source MIT-licensed skill library.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>7. <a href="https://github.com/ruvnet/ruvector" target="_blank" rel="noopener noreferrer">ruvnet/ruvector</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">RuVector is a High Performance, Real-Time, Self-Learning, Vector Graph Neural Network, and Database built in Rust.</p>
                    <p class="meta">
                        <span class="language">Rust</span> |
                        <span class="stars">836</span>
                        | <span class="today">41 stars today</span>
                    </p>
                    <p class="history">First seen: February 25, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>RuVector is a high-performance, real-time vector graph database and learning platform written in Rust that unifies vector search, graph queries, on-device LLM inference, and self-learning GNN layers in one package. It stores embeddings with HNSW (including hyperbolic variants), exposes Cypher-like graph queries, and applies SONA/GNN learning so search quality improves from usage; it supports local model runtimes (GGUF with Metal/CUDA/ANE), 46 attention mechanisms, sublinear solvers, and SQL-accessible math and topological routines. Operationally it can ship as a single .rvf cognitive container that boots as a Linux microservice, accelerates hot paths with eBPF, runs in-browser via a tiny WASM runtime, and maintains tamper-evident witness chains plus copy-on-write branching for distributed replication (Raft, multi-master vector clocks, auto-sharding). The project also integrates with Postgres/pgvector, Model Context Protocol, and orchestration platforms for agented workflows.</p>
<p>Teams building RAG systems, multi-agent orchestration, edge/offline AI, or high-throughput domain applications (e.g., genomics, diagnostics, search/recommendation) benefit from RuVector because it combines storage, real-time graph reasoning, and local inference into a single deployable stack. Its single-file cognitive container, open-source MIT license, and local/wasm runtimes reduce infrastructure and per-query dependencies while providing cryptographic auditability and horizontal scaling, which appeals to security-conscious and cost-sensitive deployments. Researchers and engineers gain access to a wide set of ML primitives (attention variants, spiking nets, routing, LoRA/EWC++) and sublinear algorithms that accelerate large-scale analytics and model routing, helping explain why the project is gaining attention in the vector/AI tooling space.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>8. <a href="https://github.com/D4Vinci/Scrapling" target="_blank" rel="noopener noreferrer">D4Vinci/Scrapling</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">üï∑Ô∏è An adaptive Web Scraping framework that handles everything from a single request to a full-scale crawl!</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">13,007</span>
                        | <span class="today">1,970 stars today</span>
                    </p>
                    <p class="history">First seen: February 25, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Scrapling is an adaptive web-scraping framework that scales from single HTTP requests to full, concurrent crawls with pause/resume and real-time streaming. Its key features include an adaptive parser that relocates elements after site changes, several fetcher types that spoof fingerprints and bypass anti-bot systems (including Cloudflare Turnstile), Playwright-backed dynamic fetchers for JS-heavy sites, session and proxy rotation, and a Scrapy-like Spider API for async, multi-session crawls with checkpoint persistence. Technically it combines fast HTTP fetchers with TLS/fingerprint impersonation, headless browser automation for dynamic content, intelligent similarity algorithms for selector recovery, and built-in serialization/streaming pipelines to deliver high-throughput, memory-efficient scraping.</p>
<p>This project benefits web scrapers, data engineers, researchers, and companies that need reliable, scalable extraction from modern, bot-protected sites because it reduces maintenance when sites change and simplifies anti-bot handling. It‚Äôs trending due to its AI integration (MCP server for cost-efficient, targeted extraction), strong developer ergonomics (full type coverage, interactive shell, Docker images), and production-ready features like proxy rotation, real-time streaming, and robust test coverage that make adoption attractive for both individual scrapers and teams.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>9. <a href="https://github.com/GVCLab/PersonaLive" target="_blank" rel="noopener noreferrer">GVCLab/PersonaLive</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">[CVPR 2026] PersonaLive! : Expressive Portrait Image Animation for Live Streaming</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">2,100</span>
                        | <span class="today">73 stars today</span>
                    </p>
                    <p class="history">First seen: February 25, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>PersonaLive is a diffusion-based framework for generating expressive, real-time portrait image animations tailored for live streaming, capable of producing effectively infinite-length videos via a streaming generation strategy. Key features include online WebUI and offline inference modes, support for acceleration backends (xFormers, TensorRT), ComfyUI integration, and downloadable pretrained weights organized for quick setup. Technically it combines modules such as a motion encoder/extractor, pose guider, temporal module, reference and denoising U-Nets to condition diffusion sampling on driving video/pose signals and a reference portrait, with optimizations for memory and latency to allow long-sequence generation on constrained GPUs. Tools are provided to convert models to TensorRT for speedups and to stream frames incrementally to maintain low latency in live settings.</p>
<p>This project will benefit researchers and developers working on portrait animation, virtual avatars/VTubers, live-streaming applications, and content creators who need real-time, personalized animation with controllable expressions and long-duration output. It is trending because it addresses a practical gap‚Äîscalable, low-latency diffusion-driven animation for live use‚Äîwhile shipping pretrained models, a usable WebUI, and multiple acceleration paths that lower the barrier to experimentation and deployment; acceptance at CVPR2026 and active community integrations (ComfyUI, TensorRT guides) have further increased visibility. Note that the authors explicitly limit use to academic research and provide a disclaimer to discourage harmful or illegal applications.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>10. <a href="https://github.com/HunxByts/GhostTrack" target="_blank" rel="noopener noreferrer">HunxByts/GhostTrack</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Useful tool to track location or mobile number</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">7,552</span>
                        | <span class="today">145 stars today</span>
                    </p>
                    <p class="history">First seen: February 25, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>GhostTrack is an open-source OSINT utility for locating IP addresses, tracking mobile numbers, and gathering information on social-media usernames via a command-line interface. Key features listed in the README include an IP Tracker (with an optional &quot;seeker&quot; helper to obtain target IPs), a Phone Tracker, and a Username Tracker, all orchestrated from a Python script (GhostTR.py). Technically it is a Python3-based tool installable via pip3 requirements and runnable on Linux or Termux, aggregating enrichment data from public APIs and online databases to present location and identifier details. The repository includes basic install and usage steps but does not detail the specific external services or data sources used.</p>
<p>This project will appeal to OSINT practitioners, security researchers, journalists, and hobbyists who need a lightweight, scriptable way to consolidate location and identifier data for investigations or research. Its relevance is driven by the growing interest in OSINT, the convenience of Python/Termux compatibility, and a focused feature set advertised in the Version 2.2 update. Users should be mindful to employ the tool ethically and in compliance with applicable laws and privacy norms.</p>
                    </div>
                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>

<script>
(() => {
    const readKey = "gtd:read_days:gh:v1";
    const dayStr = "2026-02-25";

    let stored = [];
    try {
        stored = JSON.parse(localStorage.getItem(readKey) || "[]");
        if (!Array.isArray(stored)) {
            stored = [];
        }
    } catch (_err) {
        stored = [];
    }

    if (!stored.includes(dayStr)) {
        stored.push(dayStr);
        stored.sort();
        localStorage.setItem(readKey, JSON.stringify(stored));
    }

    const collapseParam = new URLSearchParams(window.location.search).get("collapse_seen");
    const collapseSeen = collapseParam === "0" ? false : true;

    function setCollapsed(repoEl, collapsed) {
        repoEl.classList.toggle("collapsed", collapsed);
        const button = repoEl.querySelector(".repo-toggle");
        if (button) {
            button.textContent = collapsed ? "Show details" : "Hide details";
            button.setAttribute("aria-expanded", String(!collapsed));
        }
    }

    const repos = Array.from(document.querySelectorAll("section.repo[data-seen-before]"));

    repos.forEach((repoEl) => {
        const toggle = repoEl.querySelector(".repo-toggle");
        if (!toggle) {
            return;
        }

        toggle.addEventListener("click", () => {
            setCollapsed(repoEl, !repoEl.classList.contains("collapsed"));
        });
    });

    const collapseBtn = document.getElementById("collapse-seen-btn");
    const expandBtn = document.getElementById("expand-all-btn");

    if (collapseBtn) {
        collapseBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => {
                if (repoEl.dataset.seenBefore === "1") {
                    setCollapsed(repoEl, true);
                }
            });
        });
    }

    if (expandBtn) {
        expandBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => setCollapsed(repoEl, false));
        });
    }

    if (collapseSeen) {
        repos.forEach((repoEl) => {
            if (repoEl.dataset.seenBefore === "1") {
                setCollapsed(repoEl, true);
            }
        });
    }
})();
</script>

</body>
</html>
