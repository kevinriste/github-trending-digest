<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 26, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 26, 2026</h1>
        <nav>
            <a href="../">&larr; GitHub Calendar</a>
            <a href="../hn/2026-02-26/">Hacker News</a>
        </nav>
    </header>
    <main>
        <div class="repo-controls">
            <button id="collapse-seen-btn" type="button">Collapse Repos Not New Today</button>
            <button id="expand-all-btn" type="button">Expand All</button>
        </div>
        <p class="seen-help">Repos marked "Not new today" appeared on one or more previous daily pages.</p>
        <article>
            <div class="repos">

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>1. <a href="https://github.com/D4Vinci/Scrapling" target="_blank" rel="noopener noreferrer">D4Vinci/Scrapling</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">üï∑Ô∏è An adaptive Web Scraping framework that handles everything from a single request to a full-scale crawl!</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">15,636</span>
                        | <span class="today">1,656 stars today</span>
                    </p>
                    <p class="history">First seen: February 25, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Scrapling is an adaptive web-scraping framework that scales from single HTTP requests to full, concurrent crawls with pause/resume and real-time streaming. Its key features include an adaptive parser that relocates elements after site changes, several fetcher types that spoof fingerprints and bypass anti-bot systems (including Cloudflare Turnstile), Playwright-backed dynamic fetchers for JS-heavy sites, session and proxy rotation, and a Scrapy-like Spider API for async, multi-session crawls with checkpoint persistence. Technically it combines fast HTTP fetchers with TLS/fingerprint impersonation, headless browser automation for dynamic content, intelligent similarity algorithms for selector recovery, and built-in serialization/streaming pipelines to deliver high-throughput, memory-efficient scraping.</p>
<p>This project benefits web scrapers, data engineers, researchers, and companies that need reliable, scalable extraction from modern, bot-protected sites because it reduces maintenance when sites change and simplifies anti-bot handling. It‚Äôs trending due to its AI integration (MCP server for cost-efficient, targeted extraction), strong developer ergonomics (full type coverage, interactive shell, Docker images), and production-ready features like proxy rotation, real-time streaming, and robust test coverage that make adoption attractive for both individual scrapers and teams.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>2. <a href="https://github.com/huggingface/skills" target="_blank" rel="noopener noreferrer">huggingface/skills</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">No description</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">6,560</span>
                        | <span class="today">1,538 stars today</span>
                    </p>
                    <p class="history">First seen: February 22, 2026 | Consecutive daily streak: 5 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository defines &quot;skills&quot;: self-contained folders that package instructions (SKILL.md with YAML frontmatter), scripts, templates, and resources so coding agents can perform common AI/ML tasks such as dataset creation, model training, evaluation, job management, and more. It includes ready-made skills (hf CLI, datasets, evaluation, jobs, model trainer, paper publisher, tool builder, Trackio) and provides installation/manifest support for multiple agent ecosystems (Claude/Claude Code, OpenAI Codex, Google Gemini CLI, Cursor) via AGENTS.md, gemini-extension.json, and Cursor plugin files. Technically, skills are interoperable artifacts that agents load to obtain step-by-step guidance and helper tooling; the repo also provides scripts to publish/regenerate manifests and CI checks to validate metadata and marketplace listings. The result is a standardized, reusable package format that lets agents orchestrate local or Hugging Face cloud workflows reliably.</p>
<p>This project is useful for ML engineers, MLOps teams, researchers, and developers who want to automate common model and dataset workflows through coding agents and the Hugging Face platform. It reduces manual orchestration, improves reproducibility, and makes it easy to share and extend operational patterns as installable agent plugins. Its momentum comes from the growing adoption of LLM-driven coding agents, the need for cross-platform interoperability, and tight integration with Hugging Face&#x27;s tooling and cloud compute, which together lower friction for running end-to-end ML tasks.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>3. <a href="https://github.com/abhigyanpatwari/GitNexus" target="_blank" rel="noopener noreferrer">abhigyanpatwari/GitNexus</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">GitNexus: The Zero-Server Code Intelligence Engine - GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">3,971</span>
                        | <span class="today">894 stars today</span>
                    </p>
                    <p class="history">First seen: February 22, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>GitNexus is a client-side knowledge-graph engine that indexes a codebase into a graph of dependencies, call chains, clusters, and execution flows, then exposes that structure to AI agents and an interactive browser UI. It provides a CLI with an MCP server for deep agent integrations and a zero-server Web UI (WASM) so you can drop a GitHub repo or ZIP and get a navigable graph plus a Graph RAG agent. Under the hood it uses Tree-sitter for parsing, KuzuDB for graph storage, hybrid BM25+semantic search with embeddings, and exposes tools such as query, context, impact, detect_changes, rename, and raw Cypher over MCP. The system also installs agent skills and editor hooks to automatically enrich agent workflows with codebase-aware context.</p>
<p>Developers, engineering teams, and anyone building or operating AI-powered code assistants benefit because GitNexus gives agents deterministic architectural context so they stop missing dependencies, breaking call chains, or shipping blind edits. Its local-first design (persistent KuzuDB for CLI, in-browser WASM for quick exploration) preserves privacy while scaling from single-repo exploration to multi-repo MCP deployments, with integrations for Claude Code, Cursor, and OpenCode. It‚Äôs gaining traction because the rise of LLM-based developer tools has exposed a need for precise, explainable, repo-level context‚ÄîGitNexus converts code into an actionable knowledge graph that makes both small and large models more accurate and trustworthy.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>4. <a href="https://github.com/obra/superpowers" target="_blank" rel="noopener noreferrer">obra/superpowers</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">An agentic skills framework &amp; software development methodology that works.</p>
                    <p class="meta">
                        <span class="language">Shell</span> |
                        <span class="stars">62,178</span>
                        | <span class="today">1,250 stars today</span>
                    </p>
                    <p class="history">First seen: February 04, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Superpowers is a complete software development workflow for coding agents built around composable &quot;skills&quot; and starter instructions that make agents follow a consistent process. Key features include a modular skills library (TDD, systematic debugging, brainstorming, plan-writing, subagent-driven development, code review, and git worktree management), an enforced workflow that moves from spec elicitation to plan to task-level subagents, and a two-stage review system (spec compliance then code quality). Technically it ships as a plugin (Claude Code marketplace) with manual install paths for Codex and OpenCode, stores skills directly in the repository, and has agents fetch and execute skills, spawn subagents per task, and run automated verification and test-driven cycles. The repo also contains contribution guidance and update mechanics so skills can be extended and updated easily.</p>
<p>This project benefits developers, teams, and tool builders who want repeatable, evidence-driven AI-assisted engineering‚Äîespecially those who need automated testing, clear task plans, and controlled parallel work via subagents. It‚Äôs gaining traction because it addresses practical pain points in agentic coding (avoiding ad-hoc behavior, enforcing RED‚ÄëGREEN‚ÄëREFACTOR, and integrating with git workflows) while offering an easy integration path for Claude Code and extensibility via an open-source MIT-licensed skill library.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>5. <a href="https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering" target="_blank" rel="noopener noreferrer">muratcankoylan/Agent-Skills-for-Context-Engineering</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">11,006</span>
                        | <span class="today">1,042 stars today</span>
                    </p>
                    <p class="history">First seen: February 24, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a curated collection of &quot;Agent Skills&quot; for context engineering that codifies practical patterns, tools, and examples to manage the information fed into LLM-based agents. Key features include foundational material on context mechanics and degradation, architectural modules for multi-agent patterns, memory systems, tool and filesystem integration, operational modules for compression/optimization and evaluation, and cognitive BDI mental-state transformations. Technically, skills are packaged as platform-agnostic modules (Claude Code marketplace plugins, Cursor/Codex/IDE rules or standalone skill files), use progressive disclosure so full skill content loads only when activated, and ship Python-pseudocode, triggers, and installation commands that let agent runtimes discover and apply relevant skills at runtime. The repo also documents attention-aware tactics (compaction, masking, caching), LLM-as-judge evaluation methods, and hosted-agent designs for sandboxed background execution.</p>
<p>This project benefits AI engineers, multi-agent architects, ops teams, and researchers who need repeatable, production-grade patterns for conserving model attention and debugging context failures. It accelerates development by turning abstract attention mechanics into actionable skills, templates, and plugin workflows that integrate with existing agent platforms. The collection is timely and trending because managing limited context windows is a growing practical bottleneck as agentic systems scale, and because the work has received academic recognition for helping bridge manual skill engineering and dynamic evolution of agent skills.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>6. <a href="https://github.com/datawhalechina/hello-agents" target="_blank" rel="noopener noreferrer">datawhalechina/hello-agents</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">22,207</span>
                        | <span class="today">222 stars today</span>
                    </p>
                    <p class="history">First seen: February 26, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is an open-source, practice-focused tutorial and codebase that teaches how to build AI-native agents from first principles. Key features include step-by-step implementations of classic agent paradigms (ReAct, Plan-and-Solve, Reflection), a self-developed HelloAgents framework built on OpenAI APIs, memory and retrieval (RAG) modules, multi-agent communication protocols (MCP/A2A/ANP), and an Agentic-RL training pipeline from SFT to GRPO, accompanied by runnable case studies (e.g., travel assistant, DeepResearch, cyber town). Technically it combines detailed chapters with a code folder, low-code platform walkthroughs (Dify/Coze/n8n), downloadable PDF releases, and community contribution patterns to enable hands-on experimentation and end-to-end development. The project is licensed under CC BY-NC-SA 4.0 and invites issues, PRs, and community-contributed extras.</p>
<p>Practitioners who will benefit include AI developers, ML engineers, software engineers, students, and self-learners with basic Python and LLM knowledge because the material emphasizes hands-on code, frameworks, and real-world agent design patterns. It is trending because the industry focus has shifted from larger foundation models to agentic applications in 2024‚Äì2025, and this repo fills a gap by providing systematic, implementation-first guidance on building, training, evaluating, and deploying multi-agent systems. The combination of practical tutorials, a usable framework, training recipes, and curated case studies makes it a timely resource for anyone aiming to move from using LLMs to constructing production-capable agents.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>7. <a href="https://github.com/bytedance/deer-flow" target="_blank" rel="noopener noreferrer">bytedance/deer-flow</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">An open-source SuperAgent harness that researches, codes, and creates. With the help of sandboxes, memories, tools, skills and subagents, it handles different levels of tasks that could take minutes to hours.</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">20,609</span>
                        | <span class="today">59 stars today</span>
                    </p>
                    <p class="history">First seen: February 26, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>DeerFlow is an open-source &quot;super agent&quot; harness that orchestrates sub-agents, persistent memory, sandboxed execution, and extensible skills to carry out complex, multi-step tasks. Technically it is a batteries-included runtime built on LangGraph and LangChain that runs tasks inside isolated sandboxes (local, Docker, or Kubernetes), provides a filesystem and toolset (web fetch, bash, file ops), and dynamically loads Markdown-defined skills and tools while managing context via summarization and long-term memory. The lead agent can spawn parallel scoped sub-agents with their own contexts and termination rules, collect structured results, and synthesize outputs such as reports, slide decks, or web pages. Configuration is driven by config.yaml and environment keys, with Docker and local development workflows supported for fast provisioning and reproducibility.</p>
<p>DeerFlow is useful for AI researchers, data scientists, engineering teams, and content creators who need agents that do real work‚Äînot just chat‚Äîbecause it combines execution, tooling, and memory in an auditable, extensible framework. It‚Äôs trending because it addresses practical limitations of single-pass LLM interactions (execution isolation, token management, long-running tasks, and parallel decomposition), ships with ready-made skills while remaining highly customizable, and benefits from an active rewrite and community-focused tooling that make it easy to experiment with modern LLMs and production workflows.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>8. <a href="https://github.com/VectifyAI/PageIndex" target="_blank" rel="noopener noreferrer">VectifyAI/PageIndex</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">17,846</span>
                        | <span class="today">378 stars today</span>
                    </p>
                    <p class="history">First seen: February 03, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>PageIndex is an open-source, vectorless RAG system that builds a hierarchical, table-of-contents style tree index from long documents and uses LLMs to perform reasoning-driven retrieval via tree search rather than vector similarity. It parses PDFs (or markdown and page images), generates node metadata and summaries, and performs agentic in-context searches over the tree to locate the most relevant sections. Core features include no vector DB, no artificial chunking, and explainable, traceable retrieval with page/section references; an optional vision-native pipeline works directly on page images without OCR. The repository provides a CLI (runpageindex.py) with configurable model and node/page settings and can be run locally or integrated via API/MCP for chat-style document analysis.</p>
<p>PageIndex is especially useful for professionals and teams working with long, structured documents‚Äîfinance, legal, regulatory, technical manuals, and academic texts‚Äîwhere relevance requires multi-step reasoning rather than surface-level semantic similarity. By simulating human navigation and exposing reasoning paths it improves precision, auditability, and interpretability; the authors report a 98.7% result on the FinanceBench benchmark versus vector-based approaches. It reduces dependency on vector databases and chunking, simplifies pipelines (including OCR-free vision workflows), and is well suited to enterprise, research, and developer workflows that need auditable, high-precision retrieval. The approach is trending because it leverages modern LLM reasoning to address limitations of approximate semantic search for complex, domain-specific documents.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>9. <a href="https://github.com/NevaMind-AI/memU" target="_blank" rel="noopener noreferrer">NevaMind-AI/memU</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot).</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">10,923</span>
                        | <span class="today">187 stars today</span>
                    </p>
                    <p class="history">First seen: February 26, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>memU is a memory framework designed for 24/7 proactive AI agents that captures, structures, and persists user interactions so agents can anticipate and act without explicit commands. Key features include a file‚Äësystem‚Äëlike hierarchical memory model (resources, items, categories), automatic auto‚Äëcategorization, cross‚Äëreferences, persistent export/import, and a MemU bot that continuously monitors input/output to extract facts, preferences, and skills. Technically it runs as a background component that mounts conversations and documents as queryable resources, maintains summaries and links in a DB, and reduces LLM token costs by caching and injecting compact context rather than resending long histories. The repo includes runnable examples (e.g., examples/proactive/proactive.py) showing how the agent and MemU bot synchronize in a continuous loop to update memory and drive proactive suggestions.</p>
<p>Developers and teams building always‚Äëon virtual assistants, autonomous agents, and production systems requiring persistent user state (personal assistants, email triage, trading monitors) will benefit most from memU. By lowering ongoing LLM costs, providing structured long‚Äëterm context, and enabling proactive prediction and task automation, it makes continuous, evolving agents practical for enterprises and power users. The project is timely because demand for cost‚Äëefficient, contextualized, always‚Äëonline AI is growing, and memU addresses operational challenges like scalability, persistence, and fast retrieval. It also markets itself as an easy-to-use alternative to agent frameworks such as OpenClaw, reducing integration friction for teams adding long‚Äëterm memory.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>10. <a href="https://github.com/ruvnet/ruvector" target="_blank" rel="noopener noreferrer">ruvnet/ruvector</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">RuVector is a High Performance, Real-Time, Self-Learning, Vector Graph Neural Network, and Database built in Rust.</p>
                    <p class="meta">
                        <span class="language">Rust</span> |
                        <span class="stars">1,275</span>
                        | <span class="today">437 stars today</span>
                    </p>
                    <p class="history">First seen: February 25, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>RuVector is a high-performance, real-time vector graph database and learning platform written in Rust that unifies vector search, graph queries, on-device LLM inference, and self-learning GNN layers in one package. It stores embeddings with HNSW (including hyperbolic variants), exposes Cypher-like graph queries, and applies SONA/GNN learning so search quality improves from usage; it supports local model runtimes (GGUF with Metal/CUDA/ANE), 46 attention mechanisms, sublinear solvers, and SQL-accessible math and topological routines. Operationally it can ship as a single .rvf cognitive container that boots as a Linux microservice, accelerates hot paths with eBPF, runs in-browser via a tiny WASM runtime, and maintains tamper-evident witness chains plus copy-on-write branching for distributed replication (Raft, multi-master vector clocks, auto-sharding). The project also integrates with Postgres/pgvector, Model Context Protocol, and orchestration platforms for agented workflows.</p>
<p>Teams building RAG systems, multi-agent orchestration, edge/offline AI, or high-throughput domain applications (e.g., genomics, diagnostics, search/recommendation) benefit from RuVector because it combines storage, real-time graph reasoning, and local inference into a single deployable stack. Its single-file cognitive container, open-source MIT license, and local/wasm runtimes reduce infrastructure and per-query dependencies while providing cryptographic auditability and horizontal scaling, which appeals to security-conscious and cost-sensitive deployments. Researchers and engineers gain access to a wide set of ML primitives (attention variants, spiking nets, routing, LoRA/EWC++) and sublinear algorithms that accelerate large-scale analytics and model routing, helping explain why the project is gaining attention in the vector/AI tooling space.</p>
                    </div>
                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>

<script>
(() => {
    const readKey = "gtd:read_days:gh:v1";
    const dayStr = "2026-02-26";

    let stored = [];
    try {
        stored = JSON.parse(localStorage.getItem(readKey) || "[]");
        if (!Array.isArray(stored)) {
            stored = [];
        }
    } catch (_err) {
        stored = [];
    }

    if (!stored.includes(dayStr)) {
        stored.push(dayStr);
        stored.sort();
        localStorage.setItem(readKey, JSON.stringify(stored));
    }

    const collapseParam = new URLSearchParams(window.location.search).get("collapse_seen");
    const collapseSeen = collapseParam === "0" ? false : true;

    function setCollapsed(repoEl, collapsed) {
        repoEl.classList.toggle("collapsed", collapsed);
        const button = repoEl.querySelector(".repo-toggle");
        if (button) {
            button.textContent = collapsed ? "Show details" : "Hide details";
            button.setAttribute("aria-expanded", String(!collapsed));
        }
    }

    const repos = Array.from(document.querySelectorAll("section.repo[data-seen-before]"));

    repos.forEach((repoEl) => {
        const toggle = repoEl.querySelector(".repo-toggle");
        if (!toggle) {
            return;
        }

        toggle.addEventListener("click", () => {
            setCollapsed(repoEl, !repoEl.classList.contains("collapsed"));
        });
    });

    const collapseBtn = document.getElementById("collapse-seen-btn");
    const expandBtn = document.getElementById("expand-all-btn");

    if (collapseBtn) {
        collapseBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => {
                if (repoEl.dataset.seenBefore === "1") {
                    setCollapsed(repoEl, true);
                }
            });
        });
    }

    if (expandBtn) {
        expandBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => setCollapsed(repoEl, false));
        });
    }

    if (collapseSeen) {
        repos.forEach((repoEl) => {
            if (repoEl.dataset.seenBefore === "1") {
                setCollapsed(repoEl, true);
            }
        });
    }
})();
</script>

</body>
</html>
