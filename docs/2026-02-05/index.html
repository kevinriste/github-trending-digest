<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 05, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 05, 2026</h1>
        <nav>
            <a href="../">&larr; GitHub Calendar</a>
            <a href="../hn/">Hacker News</a>
        </nav>
    </header>
    <main>
        <div class="repo-controls">
            <button id="collapse-seen-btn" type="button">Collapse Repos Not New Today</button>
            <button id="expand-all-btn" type="button">Expand All</button>
        </div>
        <p class="seen-help">Repos marked "Not new today" appeared on one or more previous daily pages.</p>
        <article>
            <div class="repos">

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>1. <a href="https://github.com/thedotmack/claude-mem" target="_blank" rel="noopener noreferrer">thedotmack/claude-mem</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude&#x27;s agent-sdk), and injects relevant context back into future sessions.</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">22,858 stars</span>
                        | <span class="today">2,638 stars today</span>
                    </p>
                    <p class="history">First seen: February 02, 2026 | Consecutive daily streak: 4 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Claude-Mem is a Claude Code plugin that automatically captures Claude’s tool usage and observations during coding sessions, compresses them with the Claude agent-sdk, stores them in a local database, and injects relevant context into future sessions. Technically it uses lifecycle hook scripts to intercept session events, a Bun-managed worker HTTP service (default port 37777) with a web viewer, SQLite (with FTS5) for persistence, and a Chroma vector DB for hybrid semantic search. Retrieval is token-efficient via MCP tools (search → timeline → get_observations) implementing progressive disclosure, and the system includes configuration, privacy exclusion tags, citationable observation IDs, and a beta channel for experimental features like Endless Mode.</p>
<p>This tool benefits individual developers and teams who need continuity across ephemeral AI sessions by reducing repetitive context copying, accelerating debugging and onboarding, and preserving project knowledge and decision history. Its token-aware progressive retrieval and hybrid search make it cost-efficient for large histories, while local storage and privacy controls suit sensitive codebases. Because it integrates directly into Claude Code and leverages the agent SDK for automated summarization and injection, it’s attractive to users looking for persistent, reproducible AI-assisted coding workflows.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>2. <a href="https://github.com/openai/skills" target="_blank" rel="noopener noreferrer">openai/skills</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Skills Catalog for Codex</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">3,841 stars</span>
                        | <span class="today">746 stars today</span>
                    </p>
                    <p class="history">First seen: February 04, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository catalogs &quot;Agent Skills&quot;—self-contained folders of instructions, scripts, and resources that Codex-based AI agents can discover and use to perform specific tasks. Its main features include a curated and experimental skills layout, automatic installation of .system skills, and a $skill-installer command that adds skills by name, folder, or GitHub directory URL; each skill carries its own LICENSE.txt and follows the Agent Skills open standard. Technically, skills are packaged as directory-based modules that Codex imports at runtime (requiring a restart to pick up new skills), enabling repeatable, shareable capabilities composed of prompts, scripts, and ancillary assets. The repository therefore acts as both a registry and distribution mechanism for modular agent behaviors.</p>
<p>The project is valuable to developers, product teams, and organizations building agent-driven automation because it centralizes reusable, testable components that speed development and reduce duplication of effort. Use cases include domain-specific automation, standardized prompt and workflow sharing, rapid prototyping of agent capabilities, and collaboration across teams that need consistent agent behavior. It’s gaining traction because modular, discoverable skills align with the broader trend toward agentization and platformization of AI tooling, making it easier to scale and govern autonomous workflows.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>3. <a href="https://github.com/disler/claude-code-hooks-mastery" target="_blank" rel="noopener noreferrer">disler/claude-code-hooks-mastery</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Master Claude Code Hooks</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">2,439 stars</span>
                        | <span class="today">47 stars today</span>
                    </p>
                    <p class="history">First seen: February 05, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a practical toolkit and demo for mastering Claude Code hooks, implementing all 13 lifecycle events to add deterministic and configurable control over agent behavior. Hook logic lives as UV single-file Python scripts in .claude/hooks with inline dependency declarations, keeping each hook isolated and portable while UV handles fast dependency resolution. Key capabilities include prompt validation and context injection, pre/post tool security and transcript conversion, permission auditing, TTS-driven notifications, subagent orchestration, and automated logging of events as JSON; validators for linting and type checking (Ruff, mypy-style) and team-based builder/validator patterns are also included. The project integrates optional providers (ElevenLabs, OpenAI, Anthropic, Ollama) for TTS and LLM fallbacks and demonstrates session lifecycle management, error handling, and compaction/backups for robust agent workflows.</p>
<p>This toolkit is valuable for engineers and teams building production Claude Code agents who need observability, safety, and repeatable control over LLM-driven tooling—especially where audit logging, permission gating, and automated code-quality validation matter. It’s also useful for researchers and educators wanting a clear reference implementation of hook lifecycles, subagent patterns, and multi-provider TTS/LLM integration without polluting project environments thanks to UV scripts. Because organizations increasingly require governance, reproducibility, and orchestration for generative AI systems, a portable, test-covered hook framework that enforces security and validation around tool use is highly practical and timely.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>4. <a href="https://github.com/OpenBMB/ChatDev" target="_blank" rel="noopener noreferrer">OpenBMB/ChatDev</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">30,035 stars</span>
                        | <span class="today">227 stars today</span>
                    </p>
                    <p class="history">First seen: February 03, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>ChatDev 2.0 (DevAll) is a zero-code multi-agent orchestration platform that enables users to design, configure, and execute customized multi-agent systems via a visual workflow canvas or YAML-based instances. It exposes a web console (Vite + Vue frontend) and a Python SDK for programmatic runs, supports environment/model key configuration, real-time logs, human-in-the-loop feedback, and safe execution options (Docker/Git modes). Technically, it composes LLM-powered agents into node-based workflows and supports advanced orchestration paradigms—chain-topologies from ChatDev 1.0, MacNet DAGs for scalable collaboration, and a puppeteer-style central orchestrator optimized with reinforcement learning—to sequence, activate, and manage agents efficiently. The repository also bundles research implementations and papers (e.g., MacNet, IER, NeurIPS 2025 puppeteer branch) illustrating evolving orchestration and experience refinement techniques.</p>
<p>This project benefits developers, AI researchers, startups, and enterprises seeking to prototype or automate complex tasks (software development, data analysis, visualization, 3D generation) without writing orchestration code. By offering a zero-code interface, reusable YAML workflows, and programmatic SDK access, it reduces engineering overhead and speeds iteration while scaling to many agents and optimizing compute via learned orchestration. Researchers gain a practical testbed and reference implementations for multi-agent collaboration methods, and product teams can integrate with LLM providers through simple API key configuration. Given the surge in interest in multi-agent LLM systems, ChatDev is timely: it operationalizes collaborative agent patterns, supports human-in-the-loop and CI-friendly workflows, and bridges research ideas to deployable tooling.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>5. <a href="https://github.com/ankitects/anki" target="_blank" rel="noopener noreferrer">ankitects/anki</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Anki is a smart spaced repetition flashcard program</p>
                    <p class="meta">
                        <span class="language">Rust</span> |
                        <span class="stars">26,205 stars</span>
                        | <span class="today">28 stars today</span>
                    </p>
                    <p class="history">First seen: February 05, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Anki is the computer-version source for a spaced repetition flashcard program that helps users retain information by scheduling reviews at optimal intervals. The project implements core features such as customizable decks and card types, rich-media support, a configurable scheduling algorithm, and an extensible add‑on system. Technically, the desktop application is primarily implemented in Python with a Qt-based user interface, persists collections in a local database (SQLite), and includes build and packaging infrastructure as well as the scheduling logic that computes review intervals.</p>
<p>This project is valuable for students, medical professionals, language learners, educators, and anyone who needs reliable long‑term retention of factual knowledge because it automates review timing and supports highly customizable study content. Its open-source codebase, cross‑platform desktop builds and integrations with AnkiWeb and mobile clients make it adaptable for curricula, research, or personalized study workflows. Because spaced repetition is evidence‑backed and the app is extensible with a large community, Anki remains a trending tool for efficient, long‑term memorization.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>6. <a href="https://github.com/open-telemetry/opentelemetry-collector-contrib" target="_blank" rel="noopener noreferrer">open-telemetry/opentelemetry-collector-contrib</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Contrib repository for the OpenTelemetry Collector</p>
                    <p class="meta">
                        <span class="language">Go</span> |
                        <span class="stars">4,364 stars</span>
                        | <span class="today">3 stars today</span>
                    </p>
                    <p class="history">First seen: February 05, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>OpenTelemetry Collector Contrib is a community-maintained repository of additional components for the OpenTelemetry Collector that do not belong in the core repo, providing a broad set of receivers, processors, exporters and extensions for ingesting, transforming and exporting telemetry (traces, metrics, logs). Its main features include a large ecosystem of integrations (e.g., Jaeger, Prometheus and many vendor-specific exporters), per-signal stability levels, gated features for controlled rollouts, and clear support and contribution policies. Technically, components are implemented as pluggable factories that compose into Collector pipelines and are packaged into official &quot;contrib&quot; distributions or custom builds via the Collector Builder. The project is governed through CODEOWNERS, maintainers/approvers/triagers roles, and a PR/review process to ensure consistency and quality across components.</p>
<p>This repository is valuable for observability engineers, SREs, vendors and platform teams who need flexible, vendor-neutral telemetry pipelines and broad integration coverage beyond the core Collector. It enables organizations to ingest diverse telemetry sources, apply processing/transformation, and export to multiple backends without vendor lock-in, making it ideal for hybrid cloud and multi-tool observability stacks. The active community, clear stability gradations per signal, and ability to assemble custom Collector binaries help teams adopt new integrations quickly and safely. Its growth is driven by the demand for extensible, standard telemetry tooling and the large ecosystem of contributors adding integrations and exporters.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>7. <a href="https://github.com/Canner/WrenAI" target="_blank" rel="noopener noreferrer">Canner/WrenAI</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">⚡️ GenBI (Generative BI) queries any database in natural language, generates accurate SQL (Text-to-SQL), charts (Text-to-Chart), and AI-powered business intelligence in seconds.</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">14,014 stars</span>
                        | <span class="today">89 stars today</span>
                    </p>
                    <p class="history">First seen: February 05, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Wren AI (GenBI) is an open-source Generative BI tool that lets users query any supported database in natural language and produces precise SQL, visual charts, and AI-written insights in seconds. Key features include Text-to-SQL and Text-to-Chart generation, AI-written summaries and reports (GenBI Insights), a semantic layer (MDL models) that encodes schema/metrics/joins for governance, and an API/embeddable interface with demos (Streamlit) and managed cloud options. Technically it connects to a wide range of data sources (Postgres, Redshift, BigQuery, Snowflake, DuckDB, Trino, etc.), integrates with many LLM providers (OpenAI, Azure, Google Gemini/Vertex, Anthropic, Bedrock, Ollama, Databricks, etc.), and uses the semantic layer plus LLM prompts to constrain and generate accurate SQL and chart specifications. The project emphasizes quick local setup, documentation, and configuration examples for different models and connectors.</p>
<p>This project is valuable for data analysts, BI teams, product managers, and application developers who want to reduce the SQL learning curve and deliver decision-ready context quickly, or embed natural-language analytics into SaaS products. The semantic layer and multi-model support help keep outputs accurate and governed, making it suitable for teams that need consistent metrics and traceability in reporting. It’s trending because it combines the recent advances in LLMs with practical BI workflows—offering fast prototyping via OSS plus the scalability of a managed cloud—and because multi-vendor model support and broad connector coverage lower integration friction for enterprises.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>8. <a href="https://github.com/pedramamini/Maestro" target="_blank" rel="noopener noreferrer">pedramamini/Maestro</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Agent Orchestration Command Center</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">1,704 stars</span>
                        | <span class="today">187 stars today</span>
                    </p>
                    <p class="history">First seen: February 02, 2026 | Consecutive daily streak: 4 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Maestro is a cross-platform desktop app for orchestrating fleets of AI coding agents and projects, offering a keyboard-first interface to run, monitor, and automate parallel agent workflows. Key features include Git worktrees for isolated branch-based agents, Auto Run and filesystem playbooks for batch task execution, multi-agent group chat, mobile remote control via a built-in web server, and a CLI for headless operation. Technically it functions as a pass-through to supported AI providers (Claude Code, OpenAI Codex, OpenCode, Factory Droid), spawning fresh or resumed sessions per task, managing conversation context and workspaces, queuing messages, and integrating with git and optional remote tunneling. It also provides session discovery, token/cost tracking, analytics, and a document graph for visualizing project knowledge.</p>
<p>Maestro is aimed at developers, AI researchers, and power users who need to run multiple agentic workflows in parallel, automate repeatable playbooks, or maintain long-running unattended sessions tied to codebases. Teams benefit from isolated worktree agents that produce PR-ready outputs and from embedding agent runs into cron/CI via the CLI, while solo practitioners gain speed from keyboard-driven controls and rapid context switching. Its analytics, cost tracking, and knowledge-graph features support governance and project visibility, and the pass-through model preserves existing provider permissions and tooling—attributes that make it relevant in the growing trend of agent orchestration tools.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>9. <a href="https://github.com/nvm-sh/nvm" target="_blank" rel="noopener noreferrer">nvm-sh/nvm</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Node Version Manager - POSIX-compliant bash script to manage multiple active node.js versions</p>
                    <p class="meta">
                        <span class="language">Shell</span> |
                        <span class="stars">91,271 stars</span>
                        | <span class="today">35 stars today</span>
                    </p>
                    <p class="history">First seen: February 05, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>nvm is a POSIX-compliant bash script that lets users install, manage, and switch between multiple Node.js versions per shell and per user. It works by cloning the project into an NVMDIR (default ~/.nvm), adding a small shell snippet that sources nvm.sh into your shell profile, and exposing commands like nvm install, nvm use, and automatic .nvmrc support to select versions. The installer supports git/curl/wget, environment overrides (NVMDIR, PROFILE, NVMSOURCE), mirrors, Docker/CI non-interactive setups via BASH_ENV, and deeper shell integrations for bash, zsh, and others. Because it’s implemented as a shell script, it runs on any POSIX shell (including WSL) without binary dependencies and manipulates PATH and symlinks to switch active node/npm versions.</p>
<p>This project is valuable for developers, CI/CD engineers, and teams who need reproducible, per-project Node.js environments and easy switching between LTS or experimental releases. It removes friction from working across projects that require different Node versions, aids migration of global packages during installs, and integrates into Docker builds and automated pipelines, making it useful for both local development and build systems. Its wide adoption, simple installer, portability across platforms, and active maintenance explain its popularity and ongoing relevance in the JavaScript ecosystem.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>10. <a href="https://github.com/microsoft/qlib" target="_blank" rel="noopener noreferrer">microsoft/qlib</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Qlib is an AI-oriented Quant investment platform that aims to use AI tech to empower Quant Research, from exploring ideas to implementing productions. Qlib supports diverse ML modeling paradigms, including supervised learning, market dynamics modeling, and RL, and is now equipped withhttps://github.com/microsoft/RD-Agentto automate R&amp;D process.</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">36,601 stars</span>
                        | <span class="today">83 stars today</span>
                    </p>
                    <p class="history">First seen: February 05, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Qlib is an open‑source, AI-oriented quantitative investment platform that provides an end-to-end machine learning pipeline for alpha discovery, risk modeling, portfolio optimization, backtesting, and order execution. Its modular architecture supports diverse paradigms—supervised learning, market-dynamics modeling (including concept-drift handling), and reinforcement learning—along with many built-in models (e.g., KRNN, Transformer variants, TCN, TabNet) and utilities like point-in-time databases, high-frequency data examples, online serving, and automatic model rolling. Technically it exposes APIs and CLI tools (e.g., qrun), runs on Python 3.8–3.12 with pip/source install options, and integrates data providers and training/serving components so researchers can prototype, validate, and deploy ML-driven trading strategies. The project now also integrates RD-Agent, an LLM-based multi-agent system that automates factor mining and joint model optimization to accelerate R&amp;D workflows.</p>
<p>Qlib is valuable to quantitative researchers, data scientists, academic groups, and asset managers who need a reproducible, scalable platform to prototype, backtest, and productionize ML-driven trading strategies. Typical use cases include automated factor discovery, model selection and tuning, market-dynamics experiments, RL-based trading policy development, and low-cost online model serving for production portfolios. Its traction comes from combining a mature open-source quant stack with recent innovations—LLM-driven RD-Agent, an Auto Quant Factory, and continual additions of SOTA models and datasets—making research-to-production workflows faster, more automated, and easier to reproduce.</p>
                    </div>
                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>

<script>
(() => {
    const readKey = "gtd:read_days:gh:v1";
    const dayStr = "2026-02-05";

    let stored = [];
    try {
        stored = JSON.parse(localStorage.getItem(readKey) || "[]");
        if (!Array.isArray(stored)) {
            stored = [];
        }
    } catch (_err) {
        stored = [];
    }

    if (!stored.includes(dayStr)) {
        stored.push(dayStr);
        stored.sort();
        localStorage.setItem(readKey, JSON.stringify(stored));
    }

    const collapseParam = new URLSearchParams(window.location.search).get("collapse_seen");
    const collapseSeen = collapseParam === "0" ? false : true;

    function setCollapsed(repoEl, collapsed) {
        repoEl.classList.toggle("collapsed", collapsed);
        const button = repoEl.querySelector(".repo-toggle");
        if (button) {
            button.textContent = collapsed ? "Show details" : "Hide details";
            button.setAttribute("aria-expanded", String(!collapsed));
        }
    }

    const repos = Array.from(document.querySelectorAll("section.repo[data-seen-before]"));

    repos.forEach((repoEl) => {
        const toggle = repoEl.querySelector(".repo-toggle");
        if (!toggle) {
            return;
        }

        toggle.addEventListener("click", () => {
            setCollapsed(repoEl, !repoEl.classList.contains("collapsed"));
        });
    });

    const collapseBtn = document.getElementById("collapse-seen-btn");
    const expandBtn = document.getElementById("expand-all-btn");

    if (collapseBtn) {
        collapseBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => {
                if (repoEl.dataset.seenBefore === "1") {
                    setCollapsed(repoEl, true);
                }
            });
        });
    }

    if (expandBtn) {
        expandBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => setCollapsed(repoEl, false));
        });
    }

    if (collapseSeen) {
        repos.forEach((repoEl) => {
            if (repoEl.dataset.seenBefore === "1") {
                setCollapsed(repoEl, true);
            }
        });
    }
})();
</script>

</body>
</html>
