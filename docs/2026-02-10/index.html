<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GitHub Trending - February 10, 2026</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1>GitHub Trending Digest - February 10, 2026</h1>
        <nav>
            <a href="../">&larr; GitHub Calendar</a>
            <a href="../hn/">Hacker News</a>
        </nav>
    </header>
    <main>
        <div class="repo-controls">
            <button id="collapse-seen-btn" type="button">Collapse Repos Not New Today</button>
            <button id="expand-all-btn" type="button">Expand All</button>
        </div>
        <p class="seen-help">Repos marked "Not new today" appeared on one or more previous daily pages.</p>
        <article>
            <div class="repos">

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>1. <a href="https://github.com/KeygraphHQ/shannon" target="_blank" rel="noopener noreferrer">KeygraphHQ/shannon</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Fully autonomous AI hacker to find actual exploits in your web apps. Shannon has achieved a 96.15% success rate on the hint-free, source-aware XBOW Benchmark.</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">17,948 stars</span>
                        | <span class="today">4,144 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Shannon is an autonomous AI pentester that analyzes a target application&#x27;s source code and then autonomously hunts for and executes real-world exploits using a built-in browser and command-line actions to produce reproducible proof-of-concept attacks. Its main features include detection and validation of critical OWASP vulnerabilities (injection, XSS, SSRF, broken auth/authorization), code-aware dynamic testing, parallelized workflows, and integrations with reconnaissance/testing tools such as Nmap, Subfinder, WhatWeb, and Schemathesis. Technically it runs as containerized workflows (Docker), leverages an LLM provider (Anthropic or Claude) to drive decision-making, and exposes monitoring via a workflow UI while emitting pentester-grade reports with copy-and-paste PoCs. This repository contains Shannon Lite (AGPL-3.0) for white-box source-available testing; a commercial Pro edition adds deeper LLM-powered data-flow analysis and enterprise integrations.</p>
<p>Shannon delivers clear value to security teams, DevOps, and independent researchers who need on-demand, reproducible penetration testing to close the gap between rapid shipping and infrequent manual pentests, because it verifies exploitable issues rather than just flagging potential vulnerabilities. It‚Äôs well suited for organizations that can provide source repositories and want continuous testing or CI/CD and compliance automation (e.g., SOC 2/HIPAA evidence collection), and for red teams that need scalable, repeatable attack validation. The project is gaining attention because it combines modern LLM orchestration with established security tooling to accelerate exploit discovery, reduce false positives through validated PoCs, and lower the operational cost of frequent security validation. Small teams can experiment with the AGPL Lite, while enterprises benefit from the Pro edition‚Äôs advanced analysis and support.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>2. <a href="https://github.com/virattt/dexter" target="_blank" rel="noopener noreferrer">virattt/dexter</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">An autonomous agent for deep financial research</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">13,697 stars</span>
                        | <span class="today">1,115 stars today</span>
                    </p>
                    <p class="history">First seen: February 04, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Dexter is an autonomous financial research agent that converts complex finance questions into structured, step-by-step research plans, executes those steps using live market and financial datasets, and iterates via self-validation until it produces a confident, data-backed answer. Key features include intelligent task planning, autonomous tool selection and execution, self-reflection and error checking, and safety mechanisms such as loop detection and step limits. Technically it runs on the Bun runtime, integrates with LLM providers (OpenAI, Anthropic, XAI, OpenRouter, or local Ollama), pulls institutional-grade data via a Financial Datasets API and optional web search (Exa/Tavily), and logs every action to newline-delimited JSON scratchpads for traceability. An evaluation suite using LangSmith and an LLM-as-judge enables benchmarking on a dataset of financial questions.</p>
<p>This project is useful for sell-side and buy-side analysts, quantitative researchers, fintech engineers, and anyone needing reproducible, fast financial due diligence or idea vetting. It automates tedious data collection and initial analysis, provides auditable scratchpad logs and an eval pipeline for continuous improvement, and is extensible to different LLMs and data sources. Its traction comes from combining domain-specific tooling, live data access, and autonomous agent patterns that accelerate high-stakes research workflows while maintaining safety and traceability.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>3. <a href="https://github.com/pydantic/monty" target="_blank" rel="noopener noreferrer">pydantic/monty</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A minimal, secure Python interpreter written in Rust for use by AI</p>
                    <p class="meta">
                        <span class="language">Rust</span> |
                        <span class="stars">4,096 stars</span>
                        | <span class="today">1,291 stars today</span>
                    </p>
                    <p class="history">First seen: February 09, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>Monty is a minimal, secure Python interpreter implemented in Rust designed for running LLM-generated code inside agents. It executes a restricted but useful subset of Python, enforces complete isolation of host resources (filesystem, env, network) unless you expose specific external functions, supports async/sync calls, type checking, stdout/stderr capture, and resource limits (memory, stack, time). Technically it embeds a custom Python runtime with no CPython dependency, is serializable (can snapshot parsed code and in-flight execution to bytes), and can be called from Rust, Python, or JavaScript with microsecond-scale startup and comparable runtime performance to CPython. It intentionally omits most of the stdlib and third-party libraries and currently lacks some language features (classes, match) while under active development.</p>
<p>Monty is valuable to teams building AI agents, tool-call frameworks, and code-mode workflows that need low-latency, safe execution of model-written code without the overhead and risk of container sandboxes. Developers who want deterministic, auditable interactions between LLMs and host functions‚Äîplus the ability to cache and resume interpreter state across processes‚Äîwill benefit most. Its momentum stems from practical demand for faster, simpler, and safer in-process code execution for agents (e.g., Pydantic AI, Anthropic-style tool calling, and Cloudflare codemode), filling a gap between unsafe direct execution and heavyweight sandboxing.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>4. <a href="https://github.com/hsliuping/TradingAgents-CN" target="_blank" rel="noopener noreferrer">hsliuping/TradingAgents-CN</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Âü∫‰∫éÂ§öÊô∫ËÉΩ‰ΩìLLMÁöÑ‰∏≠ÊñáÈáëËûç‰∫§ÊòìÊ°ÜÊû∂ - TradingAgents‰∏≠ÊñáÂ¢ûÂº∫Áâà</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">16,390 stars</span>
                        | <span class="today">149 stars today</span>
                    </p>
                    <p class="history">First seen: February 10, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>TradingAgents-CN is a Chinese-enhanced fork of the TradingAgents multi-agent, LLM-driven financial research and simulated trading framework that focuses on A‚Äëshare, HK and US markets for learning and research. It centralizes multiple LLM providers (OpenAI, Google, domestic models) and implements multi-agent orchestration for tasks such as intelligent news analysis, multi-source data aggregation, automated model selection, stock screening, simulated trading and professional report export. Technically the project uses a FastAPI backend and Vue 3 frontend (noting these directories are treated as proprietary), MongoDB + Redis for storage/caching, RESTful APIs with WebSocket/SSE for realtime updates, Docker multi-architecture deployment, and integrations with Chinese data sources like Tushare/AkShare/BaoStock. The repository adopts a mixed license‚Äîmost code under Apache‚Äë2.0 while app/ and frontend/ are proprietary and require commercial authorization‚Äîand explicitly positions the platform for research/education rather than live trading.</p>
<p>This project is useful for researchers, educators, quant developers and hobbyists who want a packaged, Chinese-localized platform to prototype LLM-driven multi-agent workflows, backtest strategies, analyze news sentiment, and generate reproducible reports without building infrastructure from scratch. Its value comes from multi‚ÄëLLM vendor flexibility, containerized deployment, realtime UI/monitoring, and prebuilt integrations with Chinese market data, which lower the barrier for experimentation and teaching. The repo is trending because it combines cutting-edge LLM orchestration with practical deployment and Chinese market focus amid growing interest in AI for finance, though prospective users should respect the licensing limits and the disclaimer against using outputs as investment advice.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>5. <a href="https://github.com/iOfficeAI/AionUi" target="_blank" rel="noopener noreferrer">iOfficeAI/AionUi</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Free, local, open-source 24/7 Cowork and OpenClaw for Gemini CLI, Claude Code, Codex, OpenCode, Qwen Code, Goose CLI, Auggie, and more | üåü Star if you like it!</p>
                    <p class="meta">
                        <span class="language">TypeScript</span> |
                        <span class="stars">13,985 stars</span>
                        | <span class="today">673 stars today</span>
                    </p>
                    <p class="history">First seen: February 09, 2026 | Consecutive daily streak: 2 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>AionUi is a free, open-source multi-agent desktop and WebUI that provides a unified graphical interface for command-line AI tools (with a built-in Gemini CLI out of the box) and auto-detects and integrates local CLIs such as Claude Code, Codex, Qwen Code, Goose AI, OpenClaw and others. Its main features include multi-session/local storage with independent conversation contexts, scheduled task automation, smart file management (batch rename, classification, merging), real-time previews for 9+ file formats, AI image generation/editing, and an extensible assistants/skills ecosystem (pptx, pdf, mermaid, etc.). Technically it runs as a cross-platform (macOS/Windows/Linux) WebUI and desktop app that orchestrates local and remote models via direct CLI integration or model gateways (NewAPI), supports local model runtimes like Ollama/LM Studio, and exposes remote access through WebUI and chat platforms (Telegram, Feishu/Lark) while keeping data stored locally.</p>
<p>AionUi is valuable for developers, data analysts, knowledge workers, and teams who rely on multiple command-line AI tools but need persistent sessions, file-centric automation, and an easier GUI-driven workflow; it streamlines office automation tasks like scheduled reports, batch file processing, and document generation. Its cross-platform, multi-model support and local-data focus make it a compelling, cost-free alternative to vendor-locked tools (e.g., Claude Cowork), and its extensible assistants and remote access options explain its traction among users looking to run 24/7 AI assistants and integrate AI into everyday workflows.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>6. <a href="https://github.com/public-apis/public-apis" target="_blank" rel="noopener noreferrer">public-apis/public-apis</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A collective list of free APIs</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">397,364 stars</span>
                        | <span class="today">410 stars today</span>
                    </p>
                    <p class="history">First seen: February 10, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a community-maintained, manually curated directory of public APIs, organized into categories and presented primarily as Markdown tables in the README. Its main features include extensive categorized listings (Animals, Anime, Anti‚ÄëMalware, etc.), metadata for each API such as authentication type, HTTPS and CORS support, short descriptions, and links; the project also provides a contributing guide and an API endpoint for programmatic access. Technically it is hosted on GitHub and maintained via issues and pull requests, with human-readable tables that are often mirrored or consumed in machine-readable forms so developers can search, filter, or integrate the catalogue into tools and workflows.</p>
<p>The project is valuable to developers, product teams, educators, and hobbyists who need a fast way to discover and compare free APIs for prototyping, production features, or learning. Because it is community-curated and regularly updated, it reduces time spent searching for services and surfaces alternatives across many domains while showing key integration details up front. Its breadth, ease of contribution, and utility as a single reference point explain its popularity and why it‚Äôs commonly used in hackathons, startups, and other API-driven projects.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>7. <a href="https://github.com/github/gh-aw" target="_blank" rel="noopener noreferrer">github/gh-aw</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">GitHub Agentic Workflows</p>
                    <p class="meta">
                        <span class="language">Go</span> |
                        <span class="stars">1,015 stars</span>
                        | <span class="today">260 stars today</span>
                    </p>
                    <p class="history">First seen: February 10, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>GitHub Agentic Workflows lets you describe agentic workflows in natural-language Markdown and execute them inside GitHub Actions, effectively combining Actions, autonomous agents, and built-in safety. Its main features include a Quick Start, workflow types and examples, Peli‚Äôs Agent Factory guided library, and extensive guardrails such as read-only-by-default run contexts, sanitized safe-outputs for writes, sandboxed execution, network isolation, SHA-pinned dependencies, tool allow-listing, compile-time validation, and human approval gates. Technically, the system parses Markdown workflows into actionable steps that invoke models and tools through controlled interfaces, with companion components like the AWF for egress control and the MCP Gateway for routed model calls to enforce policy and observability. The design emphasizes multilayered security and supply-chain protections so autonomous actions can be audited and constrained within repository CI/CD.</p>
<p>This project is valuable for developer teams, platform engineers, and security/DevOps groups who want to automate repository tasks‚Äîsuch as issue triage, code generation, dependency updates, and release orchestration‚Äîwhile maintaining rigorous safety and auditability. Organizations that need reproducible, policy-driven automation with human-in-the-loop approvals will benefit from the guardrails and enterprise-friendly controls. It‚Äôs trending because of the rapid adoption of LLM-driven agents to augment developer workflows and the demand for tightly integrated, secure automation within GitHub‚Äôs ecosystem. The combination of agentic convenience and explicit safety mechanisms makes it attractive for teams exploring trustworthy AI-assisted CI/CD.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>8. <a href="https://github.com/Shubhamsaboo/awesome-llm-apps" target="_blank" rel="noopener noreferrer">Shubhamsaboo/awesome-llm-apps</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p>
                    <p class="meta">
                        <span class="language">Python</span> |
                        <span class="stars">93,264 stars</span>
                        | <span class="today">227 stars today</span>
                    </p>
                    <p class="history">First seen: February 10, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>This repository is a curated collection of LLM-powered applications and templates showcasing Retrieval-Augmented Generation (RAG), AI agents, multi-agent teams, MCP, voice agents, and related tooling across OpenAI, Anthropic, Google Gemini, xAI and open-source models like Qwen and Llama. It organizes starter and advanced projects‚Äîagentic RAG, memory-enabled chat, voice/RAG agents, MCP integrations, multi-agent orchestration, and optimization/fine-tuning tutorials‚Äîeach with project-specific READMEs and run instructions. Technically the examples demonstrate embedding-based retrieval, agent orchestration patterns (function calling, tools, Pydantic structured outputs), hybrid local/cloud deployments, and workflows for fine-tuning and cost/context optimization, with reproducible setup via pip requirements and per-project code.</p>
<p>The collection provides practical blueprints for developers, researchers, and product teams to prototype, compare, and deploy LLM applications or learn agent design patterns and RAG pipelines. It‚Äôs useful for anyone building conversational apps, knowledge assistants, voice interfaces, autonomous agents, and domain-specific retrieval systems because it consolidates interoperable examples across major and open-source models. Its popularity stems from the rapid rise of agentic and multimodal LLM use cases, broad model support, and curated, well-documented reference implementations that accelerate adoption and experimentation.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="0">
                <div class="repo-header-row">
                    <h3>9. <a href="https://github.com/gitbutlerapp/gitbutler" target="_blank" rel="noopener noreferrer">gitbutlerapp/gitbutler</a> </h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte</p>
                    <p class="meta">
                        <span class="language">Rust</span> |
                        <span class="stars">18,697 stars</span>
                        | <span class="today">376 stars today</span>
                    </p>
                    <p class="history">First seen: February 10, 2026 | Consecutive daily streak: 1 day</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>GitButler is a Git-based version-control client that layers a friendlier, feature-rich UI and workflow on top of any existing Git repository. Its main features include stacked and parallel branches, drag-and-drop or CLI commit manipulation (uncommit, reword, amend, move, split, squash), an undo timeline that logs operations, first-class conflict handling, forge integrations (GitHub/GitLab) and built‚Äëin AI helpers for messages, branch names and PR content. The app is a Tauri desktop application with a Svelte + TypeScript frontend and a Rust backend; the same Rust engine powers the standalone &quot;but&quot; CLI so the desktop and CLI experiences share core logic. Operations are designed to restack commits automatically and make rebases and history edits straightforward without needing interactive rebase.</p>
<p>This project is valuable to individual developers, multi‚Äëdeveloper teams, maintainers and anyone who wants safer, more fluid history editing and parallel workstreams‚Äîespecially where automation or AI agents interact with repos. It reduces costly rebase and merge friction, speeds up PR workflows via forge integration, and provides recoverable operations through its undo timeline, making it attractive for code reviewers and release managers. GitButler is trending because it addresses long‚Äëstanding Git UX pain points with modern tooling (Tauri/Rust/Svelte), integrates AI and agent workflows, and offers a powerful drop‚Äëin replacement for typical Git client workflows.</p>
                    </div>
                </div>
            </section>

            <section class="repo" data-seen-before="1">
                <div class="repo-header-row">
                    <h3>10. <a href="https://github.com/microsoft/litebox" target="_blank" rel="noopener noreferrer">microsoft/litebox</a> <span class="seen-badge">Not new today</span></h3>
                    <button type="button" class="repo-toggle" aria-expanded="true">Hide details</button>
                </div>
                <div class="repo-body">
                    <p class="description">A security-focused library OS supporting kernel- and user-mode execution</p>
                    <p class="meta">
                        <span class="language">Rust</span> |
                        <span class="stars">1,765 stars</span>
                        | <span class="today">354 stars today</span>
                    </p>
                    <p class="history">First seen: February 08, 2026 | Consecutive daily streak: 3 days</p>
                    <div class="ai-summary">
                        <h4>Analysis</h4>
                        <p>LiteBox is a sandboxing library OS that minimizes the host interface to reduce attack surface while enabling both kernel- and user-mode execution. It provides a Rust-y, nix/rustix-inspired &quot;North&quot; API that is paired with pluggable &quot;South&quot; Platform backends, allowing a wide variety of North‚ÄìSouth combinations and easy interoperation of shims and platforms. Technically, the project is modular: the North surface exposes POSIX-like primitives to runtimes and applications, and the South adapters implement those primitives against different hosts (Windows, Linux, SEV SNP, OP-TEE, LVBS, etc.), enabling unmodified binaries or constrained workloads to run across environments.</p>
<p>The project is valuable for security-focused system and platform developers, cloud and virtualization engineers, and anyone needing portable sandboxing or compatibility layers (for example, running Linux programs on Windows or isolating Linux workloads). Its pluggable architecture and focus on minimizing host interfaces make it attractive for mitigating attack surface in sensitive deployments, integrating with enclave technologies, and experimenting with alternative runtime models. Growing interest in Rust-based systems, supply-chain security, and hardware-backed isolation helps explain why a flexible library OS like LiteBox is gaining attention.</p>
                    </div>
                </div>
            </section>

            </div>
        </article>
    </main>
    <footer>
        <p>Generated automatically. Data from <a href="https://github.com/trending">GitHub Trending</a>.</p>
    </footer>

<script>
(() => {
    const readKey = "gtd:read_days:gh:v1";
    const dayStr = "2026-02-10";

    let stored = [];
    try {
        stored = JSON.parse(localStorage.getItem(readKey) || "[]");
        if (!Array.isArray(stored)) {
            stored = [];
        }
    } catch (_err) {
        stored = [];
    }

    if (!stored.includes(dayStr)) {
        stored.push(dayStr);
        stored.sort();
        localStorage.setItem(readKey, JSON.stringify(stored));
    }

    const collapseParam = new URLSearchParams(window.location.search).get("collapse_seen");
    const collapseSeen = collapseParam === "0" ? false : true;

    function setCollapsed(repoEl, collapsed) {
        repoEl.classList.toggle("collapsed", collapsed);
        const button = repoEl.querySelector(".repo-toggle");
        if (button) {
            button.textContent = collapsed ? "Show details" : "Hide details";
            button.setAttribute("aria-expanded", String(!collapsed));
        }
    }

    const repos = Array.from(document.querySelectorAll("section.repo[data-seen-before]"));

    repos.forEach((repoEl) => {
        const toggle = repoEl.querySelector(".repo-toggle");
        if (!toggle) {
            return;
        }

        toggle.addEventListener("click", () => {
            setCollapsed(repoEl, !repoEl.classList.contains("collapsed"));
        });
    });

    const collapseBtn = document.getElementById("collapse-seen-btn");
    const expandBtn = document.getElementById("expand-all-btn");

    if (collapseBtn) {
        collapseBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => {
                if (repoEl.dataset.seenBefore === "1") {
                    setCollapsed(repoEl, true);
                }
            });
        });
    }

    if (expandBtn) {
        expandBtn.addEventListener("click", () => {
            repos.forEach((repoEl) => setCollapsed(repoEl, false));
        });
    }

    if (collapseSeen) {
        repos.forEach((repoEl) => {
            if (repoEl.dataset.seenBefore === "1") {
                setCollapsed(repoEl, true);
            }
        });
    }
})();
</script>

</body>
</html>
